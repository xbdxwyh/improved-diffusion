{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b563c307",
   "metadata": {},
   "source": [
    "# 0. 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e339f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ced739",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff8d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "         [transforms.ToTensor(),\n",
    "          transforms.Resize([64,64]),\n",
    "          transforms.Normalize(\n",
    "              (0.5,0.5,0.5), \n",
    "              (0.5,0.5,0.5), \n",
    "          )\n",
    "         ]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5423ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='F:/Datasets/',\n",
    "                                     #train=True,\n",
    "                                     transform=transform,\n",
    "                                     download=True)\n",
    "\n",
    "# 数据加载器\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b94912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ier = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ced4abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in data_loader:\n",
    "    break\n",
    "\n",
    "i[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5ba9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image(i[0],\"show.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842c816",
   "metadata": {},
   "source": [
    "# 1. 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e4427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from improved_diffusion.unet import UNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ecdc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    image_size,\n",
    "    num_channels,\n",
    "    num_res_blocks,\n",
    "    learn_sigma,\n",
    "    class_cond,\n",
    "    use_checkpoint,\n",
    "    attention_resolutions,\n",
    "    num_heads,\n",
    "    num_heads_upsample,\n",
    "    use_scale_shift_norm,\n",
    "    dropout,\n",
    "):\n",
    "    if image_size == 256:\n",
    "        channel_mult = (1, 1, 2, 2, 4, 4)\n",
    "    elif image_size == 64:\n",
    "        channel_mult = (1, 2, 3, 4)\n",
    "    elif image_size == 32:\n",
    "        channel_mult = (1, 2, 2, 2)\n",
    "    else:\n",
    "        raise ValueError(f\"unsupported image size: {image_size}\")\n",
    "\n",
    "    attention_ds = []\n",
    "    if attention_resolutions != \"\" and attention_resolutions != []:\n",
    "        for res in attention_resolutions.split(\",\"):\n",
    "            attention_ds.append(image_size // int(res))\n",
    "\n",
    "    return UNetModel(\n",
    "        in_channels=3,\n",
    "        model_channels=num_channels,\n",
    "        out_channels=(3 if not learn_sigma else 6),\n",
    "        num_res_blocks=num_res_blocks,\n",
    "        attention_resolutions=tuple(attention_ds),\n",
    "        dropout=dropout,\n",
    "        channel_mult=channel_mult,\n",
    "        num_classes=(NUM_CLASSES if class_cond else None),\n",
    "        use_checkpoint=use_checkpoint,\n",
    "        num_heads=num_heads,\n",
    "        num_heads_upsample=num_heads_upsample,\n",
    "        use_scale_shift_norm=use_scale_shift_norm,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd8c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个小的模型玩一玩\n",
    "unet = create_model(\n",
    "    image_size=32,\n",
    "    num_channels=128,\n",
    "    num_res_blocks=1,\n",
    "    learn_sigma=False,\n",
    "    class_cond=False,\n",
    "    use_checkpoint=False,\n",
    "    attention_resolutions=\"\",#这里是在哪几层添加Attention，为了降低计算量，我们取消这个\n",
    "    num_heads=2,# 上面已经取消了，这个没什么用\n",
    "    num_heads_upsample=-1,\n",
    "    use_scale_shift_norm=True, # 在ResBlock里用到的参数\n",
    "    dropout=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fac94593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttention()\n",
       "      (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9783a11",
   "metadata": {},
   "source": [
    "# 2. Diffusion 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "895e3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from improved_diffusion import gaussian_diffusion as gd\n",
    "from improved_diffusion.resample import create_named_schedule_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df6b45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_diffusion(\n",
    "    *,\n",
    "    steps=1000,\n",
    "    learn_sigma=False,\n",
    "    sigma_small=False,\n",
    "    noise_schedule=\"linear\",\n",
    "    use_kl=False,\n",
    "    predict_xstart=False,\n",
    "    rescale_timesteps=False,\n",
    "    rescale_learned_sigmas=False,\n",
    "):\n",
    "    betas = gd.get_named_beta_schedule(noise_schedule, steps)\n",
    "    if use_kl:\n",
    "        loss_type = gd.LossType.RESCALED_KL\n",
    "    elif rescale_learned_sigmas:\n",
    "        loss_type = gd.LossType.RESCALED_MSE\n",
    "    else:\n",
    "        loss_type = gd.LossType.MSE\n",
    "\n",
    "    return gd.GaussianDiffusion(\n",
    "        betas=betas,\n",
    "        model_mean_type=(\n",
    "            gd.ModelMeanType.EPSILON if not predict_xstart else gd.ModelMeanType.START_X\n",
    "        ),\n",
    "        model_var_type=(\n",
    "            (\n",
    "                gd.ModelVarType.FIXED_LARGE\n",
    "                if not sigma_small\n",
    "                else gd.ModelVarType.FIXED_SMALL\n",
    "            )\n",
    "            if not learn_sigma\n",
    "            else gd.ModelVarType.LEARNED_RANGE\n",
    "        ),\n",
    "        loss_type=loss_type,\n",
    "        rescale_timesteps=rescale_timesteps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d52e2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = create_gaussian_diffusion(\n",
    "    steps=1000,\n",
    "    learn_sigma=False,\n",
    "    sigma_small=False,\n",
    "    noise_schedule=\"linear\",\n",
    "    use_kl=False,\n",
    "    predict_xstart=False,\n",
    "    rescale_timesteps=False,\n",
    "    rescale_learned_sigmas=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18883648",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_sampler = create_named_schedule_sampler(\"uniform\", diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b88db",
   "metadata": {},
   "source": [
    "### 3.1 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65716639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': tensor([0.9908, 0.9853, 0.9956, 0.9963, 1.0163, 0.9856, 1.0126, 1.0150, 1.0246,\n",
       "         1.0407, 0.9959, 0.9857, 0.9793, 1.0265, 0.9994, 0.9940],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " 'loss': tensor([0.9908, 0.9853, 0.9956, 0.9963, 1.0163, 0.9856, 1.0126, 1.0150, 1.0246,\n",
       "         1.0407, 0.9959, 0.9857, 0.9793, 1.0265, 0.9994, 0.9940],\n",
       "        grad_fn=<MeanBackward1>)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion.training_losses(\n",
    "    model=unet,\n",
    "    x_start=i[0],\n",
    "    t = torch.randint(0,1000,(16,))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d768b4a",
   "metadata": {},
   "source": [
    "# 4. TrainLoop 自定义版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cae8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import blobfile as bf\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from improved_diffusion.fp16_util import (\n",
    "    make_master_params,\n",
    "    master_params_to_model_params,\n",
    "    model_grads_to_master_grads,\n",
    "    unflatten_master_params,\n",
    "    zero_grad,\n",
    ")\n",
    "\n",
    "from improved_diffusion import logger\n",
    "from improved_diffusion.nn import update_ema\n",
    "from improved_diffusion.resample import LossAwareSampler, UniformSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40723062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ImageNet experiments, this was a good default value.\n",
    "# We found that the lg_loss_scale quickly climbed to\n",
    "# 20-21 within the first ~1K steps of training.\n",
    "INITIAL_LOG_LOSS_SCALE = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f17f49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 照抄不动\n",
    "def parse_resume_step_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse filenames of the form path/to/modelNNNNNN.pt, where NNNNNN is the\n",
    "    checkpoint's number of steps.\n",
    "    \"\"\"\n",
    "    split = filename.split(\"model\")\n",
    "    if len(split) < 2:\n",
    "        return 0\n",
    "    split1 = split[-1].split(\".\")[0]\n",
    "    try:\n",
    "        return int(split1)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_blob_logdir():\n",
    "    return os.environ.get(\"DIFFUSION_BLOB_LOGDIR\", logger.get_dir())\n",
    "\n",
    "\n",
    "def find_resume_checkpoint():\n",
    "    # On your infrastructure, you may want to override this to automatically\n",
    "    # discover the latest checkpoint on your blob storage, etc.\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_ema_checkpoint(main_checkpoint, step, rate):\n",
    "    if main_checkpoint is None:\n",
    "        return None\n",
    "    filename = f\"ema_{rate}_{(step):06d}.pt\"\n",
    "    path = bf.join(bf.dirname(main_checkpoint), filename)\n",
    "    if bf.exists(path):\n",
    "        return path\n",
    "    return None\n",
    "\n",
    "\n",
    "def log_loss_dict(diffusion, ts, losses):\n",
    "    for key, values in losses.items():\n",
    "        logger.logkv_mean(key, values.mean().item())\n",
    "        # Log the quantiles (four quartiles, in particular).\n",
    "        for sub_t, sub_loss in zip(ts.cpu().numpy(), values.detach().cpu().numpy()):\n",
    "            quartile = int(4 * sub_t / diffusion.num_timesteps)\n",
    "            logger.logkv_mean(f\"{key}_q{quartile}\", sub_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e8bbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小改一下，移除dist相关东西\n",
    "def load_state_dict(path, **kwargs):\n",
    "    with bf.BlobFile(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    return th.load(io.BytesIO(data), **kwargs)\n",
    "\n",
    "def dev():\n",
    "    \"\"\"\n",
    "    Get the device to use for torch.distributed.\n",
    "    \"\"\"\n",
    "    if th.cuda.is_available():\n",
    "        return th.device(\"cuda\")\n",
    "    return th.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75386a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大改，删掉所有Dist相关的，并取消了条件生成\n",
    "class TrainLoop:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        model,\n",
    "        diffusion,\n",
    "        data,\n",
    "        batch_size,\n",
    "        microbatch,\n",
    "        lr,\n",
    "        ema_rate,\n",
    "        log_interval,\n",
    "        save_interval,\n",
    "        resume_checkpoint,\n",
    "        use_fp16=False,\n",
    "        fp16_scale_growth=1e-3,\n",
    "        schedule_sampler=None,\n",
    "        weight_decay=0.0,\n",
    "        lr_anneal_steps=0,\n",
    "    ):\n",
    "        # 尽可能保持了原始参数\n",
    "        self.model = model\n",
    "        self.diffusion = diffusion\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.microbatch = microbatch if microbatch > 0 else batch_size\n",
    "        self.lr = lr\n",
    "        self.ema_rate = (\n",
    "            [ema_rate]\n",
    "            if isinstance(ema_rate, float)\n",
    "            else [float(x) for x in ema_rate.split(\",\")]\n",
    "        )\n",
    "        self.log_interval = log_interval\n",
    "        self.save_interval = save_interval\n",
    "        self.resume_checkpoint = resume_checkpoint\n",
    "        self.use_fp16 = use_fp16\n",
    "        self.fp16_scale_growth = fp16_scale_growth\n",
    "        self.schedule_sampler = schedule_sampler or UniformSampler(diffusion)\n",
    "        self.weight_decay = weight_decay\n",
    "        self.lr_anneal_steps = lr_anneal_steps\n",
    "\n",
    "        self.step = 0\n",
    "        self.resume_step = 0\n",
    "        self.global_batch = self.batch_size\n",
    "        \n",
    "        self.model_params = list(self.model.parameters())\n",
    "        self.master_params = self.model_params\n",
    "        self.lg_loss_scale = INITIAL_LOG_LOSS_SCALE\n",
    "        self.sync_cuda = th.cuda.is_available()\n",
    "        \n",
    "        self._load_and_sync_parameters()\n",
    "        \n",
    "        if self.use_fp16:\n",
    "            self._setup_fp16()\n",
    "        \n",
    "        self.opt = AdamW(self.master_params, lr=self.lr, weight_decay=self.weight_decay)\n",
    "        if self.resume_step:\n",
    "            self._load_optimizer_state()\n",
    "            # Model was resumed, either due to a restart or a checkpoint\n",
    "            # being specified at the command line.\n",
    "            self.ema_params = [\n",
    "                self._load_ema_parameters(rate) for rate in self.ema_rate\n",
    "            ]\n",
    "        else:\n",
    "            self.ema_params = [\n",
    "                copy.deepcopy(self.master_params) for _ in range(len(self.ema_rate))\n",
    "            ]\n",
    "    def run_loop(self):\n",
    "        while (\n",
    "            not self.lr_anneal_steps\n",
    "            or self.step + self.resume_step < self.lr_anneal_steps\n",
    "        ):\n",
    "            batch, cond = next(self.data)\n",
    "            cond = {}\n",
    "            self.run_step(batch, cond)\n",
    "            if self.step % self.log_interval == 0:\n",
    "                logger.dumpkvs()\n",
    "            if self.step % self.save_interval == 0:\n",
    "                self.save()\n",
    "                # Run for a finite amount of time in integration tests.\n",
    "                if os.environ.get(\"DIFFUSION_TRAINING_TEST\", \"\") and self.step > 0:\n",
    "                    return\n",
    "            self.step += 1\n",
    "        # Save the last checkpoint if it wasn't already saved.\n",
    "        if (self.step - 1) % self.save_interval != 0:\n",
    "            self.save()\n",
    "            \n",
    "    def run_step(self, batch, cond):\n",
    "        self.forward_backward(batch, cond)\n",
    "        if self.use_fp16:\n",
    "            self.optimize_fp16()\n",
    "        else:\n",
    "            self.optimize_normal()\n",
    "        self.log_step()\n",
    "    \n",
    "    def forward_backward(self, batch, cond):\n",
    "        zero_grad(self.model_params)\n",
    "        for i in range(0, batch.shape[0], self.microbatch):\n",
    "            micro = batch[i : i + self.microbatch].to(dev())\n",
    "            # 这里取消了条件生成\n",
    "            if cond is not None and cond != {}:\n",
    "                micro_cond = {\n",
    "                    k: v[i : i + self.microbatch].to(dev())\n",
    "                    for k, v in cond.items()\n",
    "                }\n",
    "            else:\n",
    "                micro_cond = None\n",
    "            t, weights = self.schedule_sampler.sample(micro.shape[0], dev())\n",
    "            \n",
    "            # 这里取消了一大堆原始代码中为了协调分布式的一堆东西，直接计算Loss\n",
    "            losses = self.diffusion.training_losses(\n",
    "                self.model,micro,\n",
    "                t,\n",
    "                model_kwargs=micro_cond\n",
    "            )\n",
    "\n",
    "            if isinstance(self.schedule_sampler, LossAwareSampler):\n",
    "                self.schedule_sampler.update_with_local_losses(\n",
    "                    t, losses[\"loss\"].detach()\n",
    "                )\n",
    "\n",
    "            loss = (losses[\"loss\"] * weights).mean()\n",
    "            log_loss_dict(\n",
    "                self.diffusion, t, {k: v * weights for k, v in losses.items()}\n",
    "            )\n",
    "            if self.use_fp16:\n",
    "                loss_scale = 2 ** self.lg_loss_scale\n",
    "                (loss * loss_scale).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "    \n",
    "    def optimize_fp16(self):\n",
    "        if any(not th.isfinite(p.grad).all() for p in self.model_params):\n",
    "            self.lg_loss_scale -= 1\n",
    "            logger.log(f\"Found NaN, decreased lg_loss_scale to {self.lg_loss_scale}\")\n",
    "            return\n",
    "\n",
    "        model_grads_to_master_grads(self.model_params, self.master_params)\n",
    "        self.master_params[0].grad.mul_(1.0 / (2 ** self.lg_loss_scale))\n",
    "        self._log_grad_norm()\n",
    "        self._anneal_lr()\n",
    "        self.opt.step()\n",
    "        for rate, params in zip(self.ema_rate, self.ema_params):\n",
    "            update_ema(params, self.master_params, rate=rate)\n",
    "        master_params_to_model_params(self.model_params, self.master_params)\n",
    "        self.lg_loss_scale += self.fp16_scale_growth\n",
    "\n",
    "    def optimize_normal(self):\n",
    "        self._log_grad_norm()\n",
    "        self._anneal_lr()\n",
    "        self.opt.step()\n",
    "        for rate, params in zip(self.ema_rate, self.ema_params):\n",
    "            update_ema(params, self.master_params, rate=rate)\n",
    "            \n",
    "    def _log_grad_norm(self):\n",
    "        sqsum = 0.0\n",
    "        for p in self.master_params:\n",
    "            sqsum += (p.grad ** 2).sum().item()\n",
    "        logger.logkv_mean(\"grad_norm\", np.sqrt(sqsum))\n",
    "\n",
    "    def _anneal_lr(self):\n",
    "        if not self.lr_anneal_steps:\n",
    "            return\n",
    "        frac_done = (self.step + self.resume_step) / self.lr_anneal_steps\n",
    "        lr = self.lr * (1 - frac_done)\n",
    "        for param_group in self.opt.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "    \n",
    "    def _load_and_sync_parameters(self):\n",
    "        resume_checkpoint = find_resume_checkpoint() or self.resume_checkpoint\n",
    "\n",
    "        if resume_checkpoint:\n",
    "            self.resume_step = parse_resume_step_from_filename(resume_checkpoint)\n",
    "            logger.log(f\"loading model from checkpoint: {resume_checkpoint}...\")\n",
    "            self.model.load_state_dict(\n",
    "                load_state_dict(\n",
    "                    resume_checkpoint, map_location=dev()\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def save(self):\n",
    "        def save_checkpoint(rate, params):\n",
    "            state_dict = self._master_params_to_state_dict(params)\n",
    "            logger.log(f\"saving model {rate}...\")\n",
    "            if not rate:\n",
    "                filename = f\"model{(self.step+self.resume_step):06d}.pt\"\n",
    "            else:\n",
    "                filename = f\"ema_{rate}_{(self.step+self.resume_step):06d}.pt\"\n",
    "            with bf.BlobFile(bf.join(get_blob_logdir(), filename), \"wb\") as f:\n",
    "                th.save(state_dict, f)\n",
    "\n",
    "        save_checkpoint(0, self.master_params)\n",
    "        for rate, params in zip(self.ema_rate, self.ema_params):\n",
    "            save_checkpoint(rate, params)\n",
    "\n",
    "\n",
    "        with bf.BlobFile(\n",
    "            bf.join(get_blob_logdir(), f\"opt{(self.step+self.resume_step):06d}.pt\"),\n",
    "            \"wb\",\n",
    "        ) as f:\n",
    "            th.save(self.opt.state_dict(), f)\n",
    "\n",
    "    \n",
    "    def log_step(self):\n",
    "        logger.logkv(\"step\", self.step + self.resume_step)\n",
    "        logger.logkv(\"samples\", (self.step + self.resume_step + 1) * self.global_batch)\n",
    "        if self.use_fp16:\n",
    "            logger.logkv(\"lg_loss_scale\", self.lg_loss_scale)\n",
    "\n",
    "    \n",
    "    def _setup_fp16(self):\n",
    "        self.master_params = make_master_params(self.model_params)\n",
    "        self.model.convert_to_fp16()\n",
    "    \n",
    "    def _load_optimizer_state(self):\n",
    "        main_checkpoint = find_resume_checkpoint() or self.resume_checkpoint\n",
    "        opt_checkpoint = bf.join(\n",
    "            bf.dirname(main_checkpoint), f\"opt{self.resume_step:06}.pt\"\n",
    "        )\n",
    "        if bf.exists(opt_checkpoint):\n",
    "            logger.log(f\"loading optimizer state from checkpoint: {opt_checkpoint}\")\n",
    "            state_dict = load_state_dict(\n",
    "                opt_checkpoint, map_location=dev()\n",
    "            )\n",
    "            self.opt.load_state_dict(state_dict)\n",
    "    \n",
    "    def _load_ema_parameters(self, rate):\n",
    "        ema_params = copy.deepcopy(self.master_params)\n",
    "\n",
    "        main_checkpoint = find_resume_checkpoint() or self.resume_checkpoint\n",
    "        ema_checkpoint = find_ema_checkpoint(main_checkpoint, self.resume_step, rate)\n",
    "        if ema_checkpoint:\n",
    "            logger.log(f\"loading EMA from checkpoint: {ema_checkpoint}...\")\n",
    "            state_dict = load_state_dict(\n",
    "                ema_checkpoint, map_location=dist_util.dev()\n",
    "            )\n",
    "            ema_params = self._state_dict_to_master_params(state_dict)\n",
    "        return ema_params\n",
    "    \n",
    "    def _state_dict_to_master_params(self, state_dict):\n",
    "        params = [state_dict[name] for name, _ in self.model.named_parameters()]\n",
    "        if self.use_fp16:\n",
    "            return make_master_params(params)\n",
    "        else:\n",
    "            return params\n",
    "    \n",
    "    def _master_params_to_state_dict(self, master_params):\n",
    "        if self.use_fp16:\n",
    "            master_params = unflatten_master_params(\n",
    "                self.model.parameters(), master_params\n",
    "            )\n",
    "        state_dict = self.model.state_dict()\n",
    "        for i, (name, _value) in enumerate(self.model.named_parameters()):\n",
    "            assert name in state_dict\n",
    "            state_dict[name] = master_params[i]\n",
    "        return state_dict\n",
    "\n",
    "    def _state_dict_to_master_params(self, state_dict):\n",
    "        params = [state_dict[name] for name, _ in self.model.named_parameters()]\n",
    "        if self.use_fp16:\n",
    "            return make_master_params(params)\n",
    "        else:\n",
    "            return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71206d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttention()\n",
       "      (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.to(dev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a291aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainLoop(\n",
    "    model=unet,\n",
    "    diffusion=diffusion,\n",
    "    data=data_ier,\n",
    "    batch_size=4,\n",
    "    microbatch=-1,\n",
    "    lr=1e-4,\n",
    "    ema_rate=\"0.9999\",\n",
    "    log_interval=10,\n",
    "    save_interval=5000,\n",
    "    resume_checkpoint=\"\",\n",
    "    use_fp16=False,\n",
    "    fp16_scale_growth=1e-3,\n",
    "    schedule_sampler=schedule_sampler,\n",
    "    weight_decay=0.0,\n",
    "    lr_anneal_steps=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef09bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to C:\\Users\\WANGYI~1\\AppData\\Local\\Temp\\openai-2022-09-10-17-15-07-378194\n",
      "------------------------\n",
      "| grad_norm | 13.1     |\n",
      "| loss      | 1        |\n",
      "| loss_q0   | 1.01     |\n",
      "| loss_q1   | 1        |\n",
      "| loss_q2   | 1.01     |\n",
      "| loss_q3   | 0.991    |\n",
      "| mse       | 1        |\n",
      "| mse_q0    | 1.01     |\n",
      "| mse_q1    | 1        |\n",
      "| mse_q2    | 1.01     |\n",
      "| mse_q3    | 0.991    |\n",
      "| samples   | 4        |\n",
      "| step      | 0        |\n",
      "------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "------------------------\n",
      "| grad_norm | 13.2     |\n",
      "| loss      | 0.904    |\n",
      "| loss_q0   | 0.924    |\n",
      "| loss_q1   | 0.888    |\n",
      "| loss_q2   | 0.901    |\n",
      "| loss_q3   | 0.903    |\n",
      "| mse       | 0.904    |\n",
      "| mse_q0    | 0.924    |\n",
      "| mse_q1    | 0.888    |\n",
      "| mse_q2    | 0.901    |\n",
      "| mse_q3    | 0.903    |\n",
      "| samples   | 44       |\n",
      "| step      | 10       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 11.9     |\n",
      "| loss      | 0.711    |\n",
      "| loss_q0   | 0.747    |\n",
      "| loss_q1   | 0.703    |\n",
      "| loss_q2   | 0.712    |\n",
      "| loss_q3   | 0.689    |\n",
      "| mse       | 0.711    |\n",
      "| mse_q0    | 0.747    |\n",
      "| mse_q1    | 0.703    |\n",
      "| mse_q2    | 0.712    |\n",
      "| mse_q3    | 0.689    |\n",
      "| samples   | 84       |\n",
      "| step      | 20       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 10.4     |\n",
      "| loss      | 0.541    |\n",
      "| loss_q0   | 0.582    |\n",
      "| loss_q1   | 0.537    |\n",
      "| loss_q2   | 0.513    |\n",
      "| loss_q3   | 0.529    |\n",
      "| mse       | 0.541    |\n",
      "| mse_q0    | 0.582    |\n",
      "| mse_q1    | 0.537    |\n",
      "| mse_q2    | 0.513    |\n",
      "| mse_q3    | 0.529    |\n",
      "| samples   | 124      |\n",
      "| step      | 30       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 8.87     |\n",
      "| loss      | 0.395    |\n",
      "| loss_q0   | 0.454    |\n",
      "| loss_q1   | 0.377    |\n",
      "| loss_q2   | 0.385    |\n",
      "| loss_q3   | 0.378    |\n",
      "| mse       | 0.395    |\n",
      "| mse_q0    | 0.454    |\n",
      "| mse_q1    | 0.377    |\n",
      "| mse_q2    | 0.385    |\n",
      "| mse_q3    | 0.378    |\n",
      "| samples   | 164      |\n",
      "| step      | 40       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 7.62     |\n",
      "| loss      | 0.296    |\n",
      "| loss_q0   | 0.357    |\n",
      "| loss_q1   | 0.272    |\n",
      "| loss_q2   | 0.27     |\n",
      "| loss_q3   | 0.263    |\n",
      "| mse       | 0.296    |\n",
      "| mse_q0    | 0.357    |\n",
      "| mse_q1    | 0.272    |\n",
      "| mse_q2    | 0.27     |\n",
      "| mse_q3    | 0.263    |\n",
      "| samples   | 204      |\n",
      "| step      | 50       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 6.13     |\n",
      "| loss      | 0.2      |\n",
      "| loss_q0   | 0.23     |\n",
      "| loss_q1   | 0.19     |\n",
      "| loss_q2   | 0.184    |\n",
      "| loss_q3   | 0.185    |\n",
      "| mse       | 0.2      |\n",
      "| mse_q0    | 0.23     |\n",
      "| mse_q1    | 0.19     |\n",
      "| mse_q2    | 0.184    |\n",
      "| mse_q3    | 0.185    |\n",
      "| samples   | 244      |\n",
      "| step      | 60       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 4.99     |\n",
      "| loss      | 0.137    |\n",
      "| loss_q0   | 0.173    |\n",
      "| loss_q1   | 0.131    |\n",
      "| loss_q2   | 0.122    |\n",
      "| loss_q3   | 0.124    |\n",
      "| mse       | 0.137    |\n",
      "| mse_q0    | 0.173    |\n",
      "| mse_q1    | 0.131    |\n",
      "| mse_q2    | 0.122    |\n",
      "| mse_q3    | 0.124    |\n",
      "| samples   | 284      |\n",
      "| step      | 70       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 5.09     |\n",
      "| loss      | 0.115    |\n",
      "| loss_q0   | 0.167    |\n",
      "| loss_q1   | 0.0877   |\n",
      "| loss_q2   | 0.0823   |\n",
      "| loss_q3   | 0.0819   |\n",
      "| mse       | 0.115    |\n",
      "| mse_q0    | 0.167    |\n",
      "| mse_q1    | 0.0877   |\n",
      "| mse_q2    | 0.0823   |\n",
      "| mse_q3    | 0.0819   |\n",
      "| samples   | 324      |\n",
      "| step      | 80       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 3.91     |\n",
      "| loss      | 0.0844   |\n",
      "| loss_q0   | 0.149    |\n",
      "| loss_q1   | 0.0615   |\n",
      "| loss_q2   | 0.0585   |\n",
      "| loss_q3   | 0.0575   |\n",
      "| mse       | 0.0844   |\n",
      "| mse_q0    | 0.149    |\n",
      "| mse_q1    | 0.0615   |\n",
      "| mse_q2    | 0.0585   |\n",
      "| mse_q3    | 0.0575   |\n",
      "| samples   | 364      |\n",
      "| step      | 90       |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 2.87     |\n",
      "| loss      | 0.0627   |\n",
      "| loss_q0   | 0.112    |\n",
      "| loss_q1   | 0.0468   |\n",
      "| loss_q2   | 0.039    |\n",
      "| loss_q3   | 0.0404   |\n",
      "| mse       | 0.0627   |\n",
      "| mse_q0    | 0.112    |\n",
      "| mse_q1    | 0.0468   |\n",
      "| mse_q2    | 0.039    |\n",
      "| mse_q3    | 0.0404   |\n",
      "| samples   | 404      |\n",
      "| step      | 100      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 2.47     |\n",
      "| loss      | 0.0517   |\n",
      "| loss_q0   | 0.132    |\n",
      "| loss_q1   | 0.0364   |\n",
      "| loss_q2   | 0.0287   |\n",
      "| loss_q3   | 0.0282   |\n",
      "| mse       | 0.0517   |\n",
      "| mse_q0    | 0.132    |\n",
      "| mse_q1    | 0.0364   |\n",
      "| mse_q2    | 0.0287   |\n",
      "| mse_q3    | 0.0282   |\n",
      "| samples   | 444      |\n",
      "| step      | 110      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 2.2      |\n",
      "| loss      | 0.0448   |\n",
      "| loss_q0   | 0.125    |\n",
      "| loss_q1   | 0.0316   |\n",
      "| loss_q2   | 0.0217   |\n",
      "| loss_q3   | 0.0213   |\n",
      "| mse       | 0.0448   |\n",
      "| mse_q0    | 0.125    |\n",
      "| mse_q1    | 0.0316   |\n",
      "| mse_q2    | 0.0217   |\n",
      "| mse_q3    | 0.0213   |\n",
      "| samples   | 484      |\n",
      "| step      | 120      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.78     |\n",
      "| loss      | 0.0385   |\n",
      "| loss_q0   | 0.104    |\n",
      "| loss_q1   | 0.0264   |\n",
      "| loss_q2   | 0.0182   |\n",
      "| loss_q3   | 0.0177   |\n",
      "| mse       | 0.0385   |\n",
      "| mse_q0    | 0.104    |\n",
      "| mse_q1    | 0.0264   |\n",
      "| mse_q2    | 0.0182   |\n",
      "| mse_q3    | 0.0177   |\n",
      "| samples   | 524      |\n",
      "| step      | 130      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.57     |\n",
      "| loss      | 0.0321   |\n",
      "| loss_q0   | 0.0764   |\n",
      "| loss_q1   | 0.0257   |\n",
      "| loss_q2   | 0.0155   |\n",
      "| loss_q3   | 0.0144   |\n",
      "| mse       | 0.0321   |\n",
      "| mse_q0    | 0.0764   |\n",
      "| mse_q1    | 0.0257   |\n",
      "| mse_q2    | 0.0155   |\n",
      "| mse_q3    | 0.0144   |\n",
      "| samples   | 564      |\n",
      "| step      | 140      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.96     |\n",
      "| loss      | 0.0347   |\n",
      "| loss_q0   | 0.0895   |\n",
      "| loss_q1   | 0.0206   |\n",
      "| loss_q2   | 0.0134   |\n",
      "| loss_q3   | 0.0124   |\n",
      "| mse       | 0.0347   |\n",
      "| mse_q0    | 0.0895   |\n",
      "| mse_q1    | 0.0206   |\n",
      "| mse_q2    | 0.0134   |\n",
      "| mse_q3    | 0.0124   |\n",
      "| samples   | 604      |\n",
      "| step      | 150      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.06     |\n",
      "| loss      | 0.025    |\n",
      "| loss_q0   | 0.0629   |\n",
      "| loss_q1   | 0.0194   |\n",
      "| loss_q2   | 0.0109   |\n",
      "| loss_q3   | 0.00989  |\n",
      "| mse       | 0.025    |\n",
      "| mse_q0    | 0.0629   |\n",
      "| mse_q1    | 0.0194   |\n",
      "| mse_q2    | 0.0109   |\n",
      "| mse_q3    | 0.00989  |\n",
      "| samples   | 644      |\n",
      "| step      | 160      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.999    |\n",
      "| loss      | 0.0232   |\n",
      "| loss_q0   | 0.0591   |\n",
      "| loss_q1   | 0.018    |\n",
      "| loss_q2   | 0.00925  |\n",
      "| loss_q3   | 0.00774  |\n",
      "| mse       | 0.0232   |\n",
      "| mse_q0    | 0.0591   |\n",
      "| mse_q1    | 0.018    |\n",
      "| mse_q2    | 0.00925  |\n",
      "| mse_q3    | 0.00774  |\n",
      "| samples   | 684      |\n",
      "| step      | 170      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.806    |\n",
      "| loss      | 0.0205   |\n",
      "| loss_q0   | 0.0546   |\n",
      "| loss_q1   | 0.0145   |\n",
      "| loss_q2   | 0.00782  |\n",
      "| loss_q3   | 0.00626  |\n",
      "| mse       | 0.0205   |\n",
      "| mse_q0    | 0.0546   |\n",
      "| mse_q1    | 0.0145   |\n",
      "| mse_q2    | 0.00782  |\n",
      "| mse_q3    | 0.00626  |\n",
      "| samples   | 724      |\n",
      "| step      | 180      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.39     |\n",
      "| loss      | 0.0257   |\n",
      "| loss_q0   | 0.0699   |\n",
      "| loss_q1   | 0.0152   |\n",
      "| loss_q2   | 0.00764  |\n",
      "| loss_q3   | 0.00551  |\n",
      "| mse       | 0.0257   |\n",
      "| mse_q0    | 0.0699   |\n",
      "| mse_q1    | 0.0152   |\n",
      "| mse_q2    | 0.00764  |\n",
      "| mse_q3    | 0.00551  |\n",
      "| samples   | 764      |\n",
      "| step      | 190      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.26     |\n",
      "| loss      | 0.0278   |\n",
      "| loss_q0   | 0.0934   |\n",
      "| loss_q1   | 0.016    |\n",
      "| loss_q2   | 0.00717  |\n",
      "| loss_q3   | 0.00512  |\n",
      "| mse       | 0.0278   |\n",
      "| mse_q0    | 0.0934   |\n",
      "| mse_q1    | 0.016    |\n",
      "| mse_q2    | 0.00717  |\n",
      "| mse_q3    | 0.00512  |\n",
      "| samples   | 804      |\n",
      "| step      | 200      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.35     |\n",
      "| loss      | 0.0314   |\n",
      "| loss_q0   | 0.086    |\n",
      "| loss_q1   | 0.0168   |\n",
      "| loss_q2   | 0.00638  |\n",
      "| loss_q3   | 0.00521  |\n",
      "| mse       | 0.0314   |\n",
      "| mse_q0    | 0.086    |\n",
      "| mse_q1    | 0.0168   |\n",
      "| mse_q2    | 0.00638  |\n",
      "| mse_q3    | 0.00521  |\n",
      "| samples   | 844      |\n",
      "| step      | 210      |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.954    |\n",
      "| loss      | 0.0182   |\n",
      "| loss_q0   | 0.0571   |\n",
      "| loss_q1   | 0.0149   |\n",
      "| loss_q2   | 0.00608  |\n",
      "| loss_q3   | 0.00483  |\n",
      "| mse       | 0.0182   |\n",
      "| mse_q0    | 0.0571   |\n",
      "| mse_q1    | 0.0149   |\n",
      "| mse_q2    | 0.00608  |\n",
      "| mse_q3    | 0.00483  |\n",
      "| samples   | 884      |\n",
      "| step      | 220      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.2      |\n",
      "| loss      | 0.0277   |\n",
      "| loss_q0   | 0.0753   |\n",
      "| loss_q1   | 0.0142   |\n",
      "| loss_q2   | 0.00624  |\n",
      "| loss_q3   | 0.00418  |\n",
      "| mse       | 0.0277   |\n",
      "| mse_q0    | 0.0753   |\n",
      "| mse_q1    | 0.0142   |\n",
      "| mse_q2    | 0.00624  |\n",
      "| mse_q3    | 0.00418  |\n",
      "| samples   | 924      |\n",
      "| step      | 230      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.07     |\n",
      "| loss      | 0.0219   |\n",
      "| loss_q0   | 0.0674   |\n",
      "| loss_q1   | 0.0139   |\n",
      "| loss_q2   | 0.00608  |\n",
      "| loss_q3   | 0.00441  |\n",
      "| mse       | 0.0219   |\n",
      "| mse_q0    | 0.0674   |\n",
      "| mse_q1    | 0.0139   |\n",
      "| mse_q2    | 0.00608  |\n",
      "| mse_q3    | 0.00441  |\n",
      "| samples   | 964      |\n",
      "| step      | 240      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.956    |\n",
      "| loss      | 0.0185   |\n",
      "| loss_q0   | 0.0478   |\n",
      "| loss_q1   | 0.0138   |\n",
      "| loss_q2   | 0.00565  |\n",
      "| loss_q3   | 0.00398  |\n",
      "| mse       | 0.0185   |\n",
      "| mse_q0    | 0.0478   |\n",
      "| mse_q1    | 0.0138   |\n",
      "| mse_q2    | 0.00565  |\n",
      "| mse_q3    | 0.00398  |\n",
      "| samples   | 1e+03    |\n",
      "| step      | 250      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.804    |\n",
      "| loss      | 0.0215   |\n",
      "| loss_q0   | 0.0557   |\n",
      "| loss_q1   | 0.0133   |\n",
      "| loss_q2   | 0.00514  |\n",
      "| loss_q3   | 0.00372  |\n",
      "| mse       | 0.0215   |\n",
      "| mse_q0    | 0.0557   |\n",
      "| mse_q1    | 0.0133   |\n",
      "| mse_q2    | 0.00514  |\n",
      "| mse_q3    | 0.00372  |\n",
      "| samples   | 1.04e+03 |\n",
      "| step      | 260      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.72     |\n",
      "| loss      | 0.0171   |\n",
      "| loss_q0   | 0.0502   |\n",
      "| loss_q1   | 0.013    |\n",
      "| loss_q2   | 0.00469  |\n",
      "| loss_q3   | 0.0034   |\n",
      "| mse       | 0.0171   |\n",
      "| mse_q0    | 0.0502   |\n",
      "| mse_q1    | 0.013    |\n",
      "| mse_q2    | 0.00469  |\n",
      "| mse_q3    | 0.0034   |\n",
      "| samples   | 1.08e+03 |\n",
      "| step      | 270      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.931    |\n",
      "| loss      | 0.0205   |\n",
      "| loss_q0   | 0.0611   |\n",
      "| loss_q1   | 0.0131   |\n",
      "| loss_q2   | 0.00499  |\n",
      "| loss_q3   | 0.00316  |\n",
      "| mse       | 0.0205   |\n",
      "| mse_q0    | 0.0611   |\n",
      "| mse_q1    | 0.0131   |\n",
      "| mse_q2    | 0.00499  |\n",
      "| mse_q3    | 0.00316  |\n",
      "| samples   | 1.12e+03 |\n",
      "| step      | 280      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.947    |\n",
      "| loss      | 0.0198   |\n",
      "| loss_q0   | 0.0613   |\n",
      "| loss_q1   | 0.0128   |\n",
      "| loss_q2   | 0.00509  |\n",
      "| loss_q3   | 0.00317  |\n",
      "| mse       | 0.0198   |\n",
      "| mse_q0    | 0.0613   |\n",
      "| mse_q1    | 0.0128   |\n",
      "| mse_q2    | 0.00509  |\n",
      "| mse_q3    | 0.00317  |\n",
      "| samples   | 1.16e+03 |\n",
      "| step      | 290      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.867    |\n",
      "| loss      | 0.0208   |\n",
      "| loss_q0   | 0.0539   |\n",
      "| loss_q1   | 0.0127   |\n",
      "| loss_q2   | 0.00506  |\n",
      "| loss_q3   | 0.00316  |\n",
      "| mse       | 0.0208   |\n",
      "| mse_q0    | 0.0539   |\n",
      "| mse_q1    | 0.0127   |\n",
      "| mse_q2    | 0.00506  |\n",
      "| mse_q3    | 0.00316  |\n",
      "| samples   | 1.2e+03  |\n",
      "| step      | 300      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.961    |\n",
      "| loss      | 0.0219   |\n",
      "| loss_q0   | 0.0589   |\n",
      "| loss_q1   | 0.0114   |\n",
      "| loss_q2   | 0.00523  |\n",
      "| loss_q3   | 0.00337  |\n",
      "| mse       | 0.0219   |\n",
      "| mse_q0    | 0.0589   |\n",
      "| mse_q1    | 0.0114   |\n",
      "| mse_q2    | 0.00523  |\n",
      "| mse_q3    | 0.00337  |\n",
      "| samples   | 1.24e+03 |\n",
      "| step      | 310      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.578    |\n",
      "| loss      | 0.0151   |\n",
      "| loss_q0   | 0.0389   |\n",
      "| loss_q1   | 0.0118   |\n",
      "| loss_q2   | 0.00495  |\n",
      "| loss_q3   | 0.00304  |\n",
      "| mse       | 0.0151   |\n",
      "| mse_q0    | 0.0389   |\n",
      "| mse_q1    | 0.0118   |\n",
      "| mse_q2    | 0.00495  |\n",
      "| mse_q3    | 0.00304  |\n",
      "| samples   | 1.28e+03 |\n",
      "| step      | 320      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.718    |\n",
      "| loss      | 0.0174   |\n",
      "| loss_q0   | 0.0477   |\n",
      "| loss_q1   | 0.0143   |\n",
      "| loss_q2   | 0.00455  |\n",
      "| loss_q3   | 0.00285  |\n",
      "| mse       | 0.0174   |\n",
      "| mse_q0    | 0.0477   |\n",
      "| mse_q1    | 0.0143   |\n",
      "| mse_q2    | 0.00455  |\n",
      "| mse_q3    | 0.00285  |\n",
      "| samples   | 1.32e+03 |\n",
      "| step      | 330      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.636    |\n",
      "| loss      | 0.0144   |\n",
      "| loss_q0   | 0.0411   |\n",
      "| loss_q1   | 0.0112   |\n",
      "| loss_q2   | 0.00473  |\n",
      "| loss_q3   | 0.00252  |\n",
      "| mse       | 0.0144   |\n",
      "| mse_q0    | 0.0411   |\n",
      "| mse_q1    | 0.0112   |\n",
      "| mse_q2    | 0.00473  |\n",
      "| mse_q3    | 0.00252  |\n",
      "| samples   | 1.36e+03 |\n",
      "| step      | 340      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.711    |\n",
      "| loss      | 0.0203   |\n",
      "| loss_q0   | 0.0582   |\n",
      "| loss_q1   | 0.0116   |\n",
      "| loss_q2   | 0.00432  |\n",
      "| loss_q3   | 0.00246  |\n",
      "| mse       | 0.0203   |\n",
      "| mse_q0    | 0.0582   |\n",
      "| mse_q1    | 0.0116   |\n",
      "| mse_q2    | 0.00432  |\n",
      "| mse_q3    | 0.00246  |\n",
      "| samples   | 1.4e+03  |\n",
      "| step      | 350      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 1.09     |\n",
      "| loss      | 0.0249   |\n",
      "| loss_q0   | 0.0718   |\n",
      "| loss_q1   | 0.0118   |\n",
      "| loss_q2   | 0.00427  |\n",
      "| loss_q3   | 0.00259  |\n",
      "| mse       | 0.0249   |\n",
      "| mse_q0    | 0.0718   |\n",
      "| mse_q1    | 0.0118   |\n",
      "| mse_q2    | 0.00427  |\n",
      "| mse_q3    | 0.00259  |\n",
      "| samples   | 1.44e+03 |\n",
      "| step      | 360      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.903    |\n",
      "| loss      | 0.019    |\n",
      "| loss_q0   | 0.0583   |\n",
      "| loss_q1   | 0.0109   |\n",
      "| loss_q2   | 0.00504  |\n",
      "| loss_q3   | 0.00265  |\n",
      "| mse       | 0.019    |\n",
      "| mse_q0    | 0.0583   |\n",
      "| mse_q1    | 0.0109   |\n",
      "| mse_q2    | 0.00504  |\n",
      "| mse_q3    | 0.00265  |\n",
      "| samples   | 1.48e+03 |\n",
      "| step      | 370      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.857    |\n",
      "| loss      | 0.0192   |\n",
      "| loss_q0   | 0.0527   |\n",
      "| loss_q1   | 0.0112   |\n",
      "| loss_q2   | 0.00453  |\n",
      "| loss_q3   | 0.00251  |\n",
      "| mse       | 0.0192   |\n",
      "| mse_q0    | 0.0527   |\n",
      "| mse_q1    | 0.0112   |\n",
      "| mse_q2    | 0.00453  |\n",
      "| mse_q3    | 0.00251  |\n",
      "| samples   | 1.52e+03 |\n",
      "| step      | 380      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.846    |\n",
      "| loss      | 0.0153   |\n",
      "| loss_q0   | 0.048    |\n",
      "| loss_q1   | 0.0114   |\n",
      "| loss_q2   | 0.0041   |\n",
      "| loss_q3   | 0.00263  |\n",
      "| mse       | 0.0153   |\n",
      "| mse_q0    | 0.048    |\n",
      "| mse_q1    | 0.0114   |\n",
      "| mse_q2    | 0.0041   |\n",
      "| mse_q3    | 0.00263  |\n",
      "| samples   | 1.56e+03 |\n",
      "| step      | 390      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.963    |\n",
      "| loss      | 0.0173   |\n",
      "| loss_q0   | 0.0526   |\n",
      "| loss_q1   | 0.0113   |\n",
      "| loss_q2   | 0.00442  |\n",
      "| loss_q3   | 0.00258  |\n",
      "| mse       | 0.0173   |\n",
      "| mse_q0    | 0.0526   |\n",
      "| mse_q1    | 0.0113   |\n",
      "| mse_q2    | 0.00442  |\n",
      "| mse_q3    | 0.00258  |\n",
      "| samples   | 1.6e+03  |\n",
      "| step      | 400      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.85     |\n",
      "| loss      | 0.014    |\n",
      "| loss_q0   | 0.0473   |\n",
      "| loss_q1   | 0.0118   |\n",
      "| loss_q2   | 0.00404  |\n",
      "| loss_q3   | 0.00236  |\n",
      "| mse       | 0.014    |\n",
      "| mse_q0    | 0.0473   |\n",
      "| mse_q1    | 0.0118   |\n",
      "| mse_q2    | 0.00404  |\n",
      "| mse_q3    | 0.00236  |\n",
      "| samples   | 1.64e+03 |\n",
      "| step      | 410      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.767    |\n",
      "| loss      | 0.0183   |\n",
      "| loss_q0   | 0.0524   |\n",
      "| loss_q1   | 0.0117   |\n",
      "| loss_q2   | 0.00423  |\n",
      "| loss_q3   | 0.00229  |\n",
      "| mse       | 0.0183   |\n",
      "| mse_q0    | 0.0524   |\n",
      "| mse_q1    | 0.0117   |\n",
      "| mse_q2    | 0.00423  |\n",
      "| mse_q3    | 0.00229  |\n",
      "| samples   | 1.68e+03 |\n",
      "| step      | 420      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.701    |\n",
      "| loss      | 0.0174   |\n",
      "| loss_q0   | 0.05     |\n",
      "| loss_q1   | 0.0118   |\n",
      "| loss_q2   | 0.00395  |\n",
      "| loss_q3   | 0.00233  |\n",
      "| mse       | 0.0174   |\n",
      "| mse_q0    | 0.05     |\n",
      "| mse_q1    | 0.0118   |\n",
      "| mse_q2    | 0.00395  |\n",
      "| mse_q3    | 0.00233  |\n",
      "| samples   | 1.72e+03 |\n",
      "| step      | 430      |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.754    |\n",
      "| loss      | 0.0188   |\n",
      "| loss_q0   | 0.0533   |\n",
      "| loss_q1   | 0.0115   |\n",
      "| loss_q2   | 0.00402  |\n",
      "| loss_q3   | 0.00214  |\n",
      "| mse       | 0.0188   |\n",
      "| mse_q0    | 0.0533   |\n",
      "| mse_q1    | 0.0115   |\n",
      "| mse_q2    | 0.00402  |\n",
      "| mse_q3    | 0.00214  |\n",
      "| samples   | 1.76e+03 |\n",
      "| step      | 440      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.808    |\n",
      "| loss      | 0.0167   |\n",
      "| loss_q0   | 0.0461   |\n",
      "| loss_q1   | 0.0115   |\n",
      "| loss_q2   | 0.00447  |\n",
      "| loss_q3   | 0.00224  |\n",
      "| mse       | 0.0167   |\n",
      "| mse_q0    | 0.0461   |\n",
      "| mse_q1    | 0.0115   |\n",
      "| mse_q2    | 0.00447  |\n",
      "| mse_q3    | 0.00224  |\n",
      "| samples   | 1.8e+03  |\n",
      "| step      | 450      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.809    |\n",
      "| loss      | 0.0177   |\n",
      "| loss_q0   | 0.0508   |\n",
      "| loss_q1   | 0.0117   |\n",
      "| loss_q2   | 0.00397  |\n",
      "| loss_q3   | 0.00214  |\n",
      "| mse       | 0.0177   |\n",
      "| mse_q0    | 0.0508   |\n",
      "| mse_q1    | 0.0117   |\n",
      "| mse_q2    | 0.00397  |\n",
      "| mse_q3    | 0.00214  |\n",
      "| samples   | 1.84e+03 |\n",
      "| step      | 460      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.612    |\n",
      "| loss      | 0.0162   |\n",
      "| loss_q0   | 0.0493   |\n",
      "| loss_q1   | 0.0118   |\n",
      "| loss_q2   | 0.00459  |\n",
      "| loss_q3   | 0.00222  |\n",
      "| mse       | 0.0162   |\n",
      "| mse_q0    | 0.0493   |\n",
      "| mse_q1    | 0.0118   |\n",
      "| mse_q2    | 0.00459  |\n",
      "| mse_q3    | 0.00222  |\n",
      "| samples   | 1.88e+03 |\n",
      "| step      | 470      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.762    |\n",
      "| loss      | 0.0174   |\n",
      "| loss_q0   | 0.0599   |\n",
      "| loss_q1   | 0.0122   |\n",
      "| loss_q2   | 0.00403  |\n",
      "| loss_q3   | 0.0022   |\n",
      "| mse       | 0.0174   |\n",
      "| mse_q0    | 0.0599   |\n",
      "| mse_q1    | 0.0122   |\n",
      "| mse_q2    | 0.00403  |\n",
      "| mse_q3    | 0.0022   |\n",
      "| samples   | 1.92e+03 |\n",
      "| step      | 480      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.817    |\n",
      "| loss      | 0.0198   |\n",
      "| loss_q0   | 0.0716   |\n",
      "| loss_q1   | 0.0107   |\n",
      "| loss_q2   | 0.00406  |\n",
      "| loss_q3   | 0.00204  |\n",
      "| mse       | 0.0198   |\n",
      "| mse_q0    | 0.0716   |\n",
      "| mse_q1    | 0.0107   |\n",
      "| mse_q2    | 0.00406  |\n",
      "| mse_q3    | 0.00204  |\n",
      "| samples   | 1.96e+03 |\n",
      "| step      | 490      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.839    |\n",
      "| loss      | 0.0166   |\n",
      "| loss_q0   | 0.0499   |\n",
      "| loss_q1   | 0.0107   |\n",
      "| loss_q2   | 0.00415  |\n",
      "| loss_q3   | 0.00205  |\n",
      "| mse       | 0.0166   |\n",
      "| mse_q0    | 0.0499   |\n",
      "| mse_q1    | 0.0107   |\n",
      "| mse_q2    | 0.00415  |\n",
      "| mse_q3    | 0.00205  |\n",
      "| samples   | 2e+03    |\n",
      "| step      | 500      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.872    |\n",
      "| loss      | 0.0164   |\n",
      "| loss_q0   | 0.0457   |\n",
      "| loss_q1   | 0.0112   |\n",
      "| loss_q2   | 0.00373  |\n",
      "| loss_q3   | 0.00212  |\n",
      "| mse       | 0.0164   |\n",
      "| mse_q0    | 0.0457   |\n",
      "| mse_q1    | 0.0112   |\n",
      "| mse_q2    | 0.00373  |\n",
      "| mse_q3    | 0.00212  |\n",
      "| samples   | 2.04e+03 |\n",
      "| step      | 510      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.684    |\n",
      "| loss      | 0.0166   |\n",
      "| loss_q0   | 0.0509   |\n",
      "| loss_q1   | 0.0116   |\n",
      "| loss_q2   | 0.00359  |\n",
      "| loss_q3   | 0.00213  |\n",
      "| mse       | 0.0166   |\n",
      "| mse_q0    | 0.0509   |\n",
      "| mse_q1    | 0.0116   |\n",
      "| mse_q2    | 0.00359  |\n",
      "| mse_q3    | 0.00213  |\n",
      "| samples   | 2.08e+03 |\n",
      "| step      | 520      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.645    |\n",
      "| loss      | 0.0197   |\n",
      "| loss_q0   | 0.0499   |\n",
      "| loss_q1   | 0.0111   |\n",
      "| loss_q2   | 0.00383  |\n",
      "| loss_q3   | 0.00193  |\n",
      "| mse       | 0.0197   |\n",
      "| mse_q0    | 0.0499   |\n",
      "| mse_q1    | 0.0111   |\n",
      "| mse_q2    | 0.00383  |\n",
      "| mse_q3    | 0.00193  |\n",
      "| samples   | 2.12e+03 |\n",
      "| step      | 530      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.617    |\n",
      "| loss      | 0.0148   |\n",
      "| loss_q0   | 0.0456   |\n",
      "| loss_q1   | 0.0125   |\n",
      "| loss_q2   | 0.00355  |\n",
      "| loss_q3   | 0.00198  |\n",
      "| mse       | 0.0148   |\n",
      "| mse_q0    | 0.0456   |\n",
      "| mse_q1    | 0.0125   |\n",
      "| mse_q2    | 0.00355  |\n",
      "| mse_q3    | 0.00198  |\n",
      "| samples   | 2.16e+03 |\n",
      "| step      | 540      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.605    |\n",
      "| loss      | 0.0168   |\n",
      "| loss_q0   | 0.0514   |\n",
      "| loss_q1   | 0.0112   |\n",
      "| loss_q2   | 0.00392  |\n",
      "| loss_q3   | 0.00195  |\n",
      "| mse       | 0.0168   |\n",
      "| mse_q0    | 0.0514   |\n",
      "| mse_q1    | 0.0112   |\n",
      "| mse_q2    | 0.00392  |\n",
      "| mse_q3    | 0.00195  |\n",
      "| samples   | 2.2e+03  |\n",
      "| step      | 550      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.761    |\n",
      "| loss      | 0.0213   |\n",
      "| loss_q0   | 0.0609   |\n",
      "| loss_q1   | 0.0107   |\n",
      "| loss_q2   | 0.00381  |\n",
      "| loss_q3   | 0.00195  |\n",
      "| mse       | 0.0213   |\n",
      "| mse_q0    | 0.0609   |\n",
      "| mse_q1    | 0.0107   |\n",
      "| mse_q2    | 0.00381  |\n",
      "| mse_q3    | 0.00195  |\n",
      "| samples   | 2.24e+03 |\n",
      "| step      | 560      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.752    |\n",
      "| loss      | 0.0183   |\n",
      "| loss_q0   | 0.0508   |\n",
      "| loss_q1   | 0.0107   |\n",
      "| loss_q2   | 0.00378  |\n",
      "| loss_q3   | 0.00195  |\n",
      "| mse       | 0.0183   |\n",
      "| mse_q0    | 0.0508   |\n",
      "| mse_q1    | 0.0107   |\n",
      "| mse_q2    | 0.00378  |\n",
      "| mse_q3    | 0.00195  |\n",
      "| samples   | 2.28e+03 |\n",
      "| step      | 570      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.791    |\n",
      "| loss      | 0.0121   |\n",
      "| loss_q0   | 0.0355   |\n",
      "| loss_q1   | 0.0125   |\n",
      "| loss_q2   | 0.00385  |\n",
      "| loss_q3   | 0.00193  |\n",
      "| mse       | 0.0121   |\n",
      "| mse_q0    | 0.0355   |\n",
      "| mse_q1    | 0.0125   |\n",
      "| mse_q2    | 0.00385  |\n",
      "| mse_q3    | 0.00193  |\n",
      "| samples   | 2.32e+03 |\n",
      "| step      | 580      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.735    |\n",
      "| loss      | 0.0143   |\n",
      "| loss_q0   | 0.0432   |\n",
      "| loss_q1   | 0.0106   |\n",
      "| loss_q2   | 0.00394  |\n",
      "| loss_q3   | 0.00214  |\n",
      "| mse       | 0.0143   |\n",
      "| mse_q0    | 0.0432   |\n",
      "| mse_q1    | 0.0106   |\n",
      "| mse_q2    | 0.00394  |\n",
      "| mse_q3    | 0.00214  |\n",
      "| samples   | 2.36e+03 |\n",
      "| step      | 590      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.768    |\n",
      "| loss      | 0.0207   |\n",
      "| loss_q0   | 0.0698   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00396  |\n",
      "| loss_q3   | 0.00194  |\n",
      "| mse       | 0.0207   |\n",
      "| mse_q0    | 0.0698   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00396  |\n",
      "| mse_q3    | 0.00194  |\n",
      "| samples   | 2.4e+03  |\n",
      "| step      | 600      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.553    |\n",
      "| loss      | 0.0152   |\n",
      "| loss_q0   | 0.0437   |\n",
      "| loss_q1   | 0.0103   |\n",
      "| loss_q2   | 0.0034   |\n",
      "| loss_q3   | 0.00187  |\n",
      "| mse       | 0.0152   |\n",
      "| mse_q0    | 0.0437   |\n",
      "| mse_q1    | 0.0103   |\n",
      "| mse_q2    | 0.0034   |\n",
      "| mse_q3    | 0.00187  |\n",
      "| samples   | 2.44e+03 |\n",
      "| step      | 610      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.585    |\n",
      "| loss      | 0.0154   |\n",
      "| loss_q0   | 0.0537   |\n",
      "| loss_q1   | 0.011    |\n",
      "| loss_q2   | 0.00353  |\n",
      "| loss_q3   | 0.00175  |\n",
      "| mse       | 0.0154   |\n",
      "| mse_q0    | 0.0537   |\n",
      "| mse_q1    | 0.011    |\n",
      "| mse_q2    | 0.00353  |\n",
      "| mse_q3    | 0.00175  |\n",
      "| samples   | 2.48e+03 |\n",
      "| step      | 620      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.496    |\n",
      "| loss      | 0.0144   |\n",
      "| loss_q0   | 0.0431   |\n",
      "| loss_q1   | 0.0103   |\n",
      "| loss_q2   | 0.00352  |\n",
      "| loss_q3   | 0.00181  |\n",
      "| mse       | 0.0144   |\n",
      "| mse_q0    | 0.0431   |\n",
      "| mse_q1    | 0.0103   |\n",
      "| mse_q2    | 0.00352  |\n",
      "| mse_q3    | 0.00181  |\n",
      "| samples   | 2.52e+03 |\n",
      "| step      | 630      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.478    |\n",
      "| loss      | 0.0137   |\n",
      "| loss_q0   | 0.0356   |\n",
      "| loss_q1   | 0.0111   |\n",
      "| loss_q2   | 0.00356  |\n",
      "| loss_q3   | 0.00171  |\n",
      "| mse       | 0.0137   |\n",
      "| mse_q0    | 0.0356   |\n",
      "| mse_q1    | 0.0111   |\n",
      "| mse_q2    | 0.00356  |\n",
      "| mse_q3    | 0.00171  |\n",
      "| samples   | 2.56e+03 |\n",
      "| step      | 640      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.564    |\n",
      "| loss      | 0.0154   |\n",
      "| loss_q0   | 0.0423   |\n",
      "| loss_q1   | 0.0108   |\n",
      "| loss_q2   | 0.0035   |\n",
      "| loss_q3   | 0.00162  |\n",
      "| mse       | 0.0154   |\n",
      "| mse_q0    | 0.0423   |\n",
      "| mse_q1    | 0.0108   |\n",
      "| mse_q2    | 0.0035   |\n",
      "| mse_q3    | 0.00162  |\n",
      "| samples   | 2.6e+03  |\n",
      "| step      | 650      |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.562    |\n",
      "| loss      | 0.0142   |\n",
      "| loss_q0   | 0.0457   |\n",
      "| loss_q1   | 0.0113   |\n",
      "| loss_q2   | 0.00337  |\n",
      "| loss_q3   | 0.00159  |\n",
      "| mse       | 0.0142   |\n",
      "| mse_q0    | 0.0457   |\n",
      "| mse_q1    | 0.0113   |\n",
      "| mse_q2    | 0.00337  |\n",
      "| mse_q3    | 0.00159  |\n",
      "| samples   | 2.64e+03 |\n",
      "| step      | 660      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.611    |\n",
      "| loss      | 0.0133   |\n",
      "| loss_q0   | 0.0363   |\n",
      "| loss_q1   | 0.0114   |\n",
      "| loss_q2   | 0.00353  |\n",
      "| loss_q3   | 0.00173  |\n",
      "| mse       | 0.0133   |\n",
      "| mse_q0    | 0.0363   |\n",
      "| mse_q1    | 0.0114   |\n",
      "| mse_q2    | 0.00353  |\n",
      "| mse_q3    | 0.00173  |\n",
      "| samples   | 2.68e+03 |\n",
      "| step      | 670      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.627    |\n",
      "| loss      | 0.0125   |\n",
      "| loss_q0   | 0.0417   |\n",
      "| loss_q1   | 0.0106   |\n",
      "| loss_q2   | 0.00353  |\n",
      "| loss_q3   | 0.00163  |\n",
      "| mse       | 0.0125   |\n",
      "| mse_q0    | 0.0417   |\n",
      "| mse_q1    | 0.0106   |\n",
      "| mse_q2    | 0.00353  |\n",
      "| mse_q3    | 0.00163  |\n",
      "| samples   | 2.72e+03 |\n",
      "| step      | 680      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.616    |\n",
      "| loss      | 0.0122   |\n",
      "| loss_q0   | 0.0345   |\n",
      "| loss_q1   | 0.0113   |\n",
      "| loss_q2   | 0.00315  |\n",
      "| loss_q3   | 0.00163  |\n",
      "| mse       | 0.0122   |\n",
      "| mse_q0    | 0.0345   |\n",
      "| mse_q1    | 0.0113   |\n",
      "| mse_q2    | 0.00315  |\n",
      "| mse_q3    | 0.00163  |\n",
      "| samples   | 2.76e+03 |\n",
      "| step      | 690      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.69     |\n",
      "| loss      | 0.0163   |\n",
      "| loss_q0   | 0.043    |\n",
      "| loss_q1   | 0.0108   |\n",
      "| loss_q2   | 0.00356  |\n",
      "| loss_q3   | 0.00165  |\n",
      "| mse       | 0.0163   |\n",
      "| mse_q0    | 0.043    |\n",
      "| mse_q1    | 0.0108   |\n",
      "| mse_q2    | 0.00356  |\n",
      "| mse_q3    | 0.00165  |\n",
      "| samples   | 2.8e+03  |\n",
      "| step      | 700      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.509    |\n",
      "| loss      | 0.0163   |\n",
      "| loss_q0   | 0.0458   |\n",
      "| loss_q1   | 0.0108   |\n",
      "| loss_q2   | 0.00353  |\n",
      "| loss_q3   | 0.00155  |\n",
      "| mse       | 0.0163   |\n",
      "| mse_q0    | 0.0458   |\n",
      "| mse_q1    | 0.0108   |\n",
      "| mse_q2    | 0.00353  |\n",
      "| mse_q3    | 0.00155  |\n",
      "| samples   | 2.84e+03 |\n",
      "| step      | 710      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.556    |\n",
      "| loss      | 0.014    |\n",
      "| loss_q0   | 0.0415   |\n",
      "| loss_q1   | 0.011    |\n",
      "| loss_q2   | 0.00354  |\n",
      "| loss_q3   | 0.00164  |\n",
      "| mse       | 0.014    |\n",
      "| mse_q0    | 0.0415   |\n",
      "| mse_q1    | 0.011    |\n",
      "| mse_q2    | 0.00354  |\n",
      "| mse_q3    | 0.00164  |\n",
      "| samples   | 2.88e+03 |\n",
      "| step      | 720      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.692    |\n",
      "| loss      | 0.0156   |\n",
      "| loss_q0   | 0.0458   |\n",
      "| loss_q1   | 0.00958  |\n",
      "| loss_q2   | 0.00314  |\n",
      "| loss_q3   | 0.00161  |\n",
      "| mse       | 0.0156   |\n",
      "| mse_q0    | 0.0458   |\n",
      "| mse_q1    | 0.00958  |\n",
      "| mse_q2    | 0.00314  |\n",
      "| mse_q3    | 0.00161  |\n",
      "| samples   | 2.92e+03 |\n",
      "| step      | 730      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.551    |\n",
      "| loss      | 0.0172   |\n",
      "| loss_q0   | 0.0516   |\n",
      "| loss_q1   | 0.0107   |\n",
      "| loss_q2   | 0.0028   |\n",
      "| loss_q3   | 0.00152  |\n",
      "| mse       | 0.0172   |\n",
      "| mse_q0    | 0.0516   |\n",
      "| mse_q1    | 0.0107   |\n",
      "| mse_q2    | 0.0028   |\n",
      "| mse_q3    | 0.00152  |\n",
      "| samples   | 2.96e+03 |\n",
      "| step      | 740      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.58     |\n",
      "| loss      | 0.0189   |\n",
      "| loss_q0   | 0.05     |\n",
      "| loss_q1   | 0.00974  |\n",
      "| loss_q2   | 0.00336  |\n",
      "| loss_q3   | 0.00151  |\n",
      "| mse       | 0.0189   |\n",
      "| mse_q0    | 0.05     |\n",
      "| mse_q1    | 0.00974  |\n",
      "| mse_q2    | 0.00336  |\n",
      "| mse_q3    | 0.00151  |\n",
      "| samples   | 3e+03    |\n",
      "| step      | 750      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.763    |\n",
      "| loss      | 0.0172   |\n",
      "| loss_q0   | 0.0597   |\n",
      "| loss_q1   | 0.00898  |\n",
      "| loss_q2   | 0.00322  |\n",
      "| loss_q3   | 0.00158  |\n",
      "| mse       | 0.0172   |\n",
      "| mse_q0    | 0.0597   |\n",
      "| mse_q1    | 0.00898  |\n",
      "| mse_q2    | 0.00322  |\n",
      "| mse_q3    | 0.00158  |\n",
      "| samples   | 3.04e+03 |\n",
      "| step      | 760      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.744    |\n",
      "| loss      | 0.0131   |\n",
      "| loss_q0   | 0.0515   |\n",
      "| loss_q1   | 0.0114   |\n",
      "| loss_q2   | 0.00336  |\n",
      "| loss_q3   | 0.0017   |\n",
      "| mse       | 0.0131   |\n",
      "| mse_q0    | 0.0515   |\n",
      "| mse_q1    | 0.0114   |\n",
      "| mse_q2    | 0.00336  |\n",
      "| mse_q3    | 0.0017   |\n",
      "| samples   | 3.08e+03 |\n",
      "| step      | 770      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.805    |\n",
      "| loss      | 0.0151   |\n",
      "| loss_q0   | 0.037    |\n",
      "| loss_q1   | 0.0109   |\n",
      "| loss_q2   | 0.0038   |\n",
      "| loss_q3   | 0.00176  |\n",
      "| mse       | 0.0151   |\n",
      "| mse_q0    | 0.037    |\n",
      "| mse_q1    | 0.0109   |\n",
      "| mse_q2    | 0.0038   |\n",
      "| mse_q3    | 0.00176  |\n",
      "| samples   | 3.12e+03 |\n",
      "| step      | 780      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.795    |\n",
      "| loss      | 0.0166   |\n",
      "| loss_q0   | 0.0541   |\n",
      "| loss_q1   | 0.0104   |\n",
      "| loss_q2   | 0.00348  |\n",
      "| loss_q3   | 0.00174  |\n",
      "| mse       | 0.0166   |\n",
      "| mse_q0    | 0.0541   |\n",
      "| mse_q1    | 0.0104   |\n",
      "| mse_q2    | 0.00348  |\n",
      "| mse_q3    | 0.00174  |\n",
      "| samples   | 3.16e+03 |\n",
      "| step      | 790      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.699    |\n",
      "| loss      | 0.0142   |\n",
      "| loss_q0   | 0.0525   |\n",
      "| loss_q1   | 0.0106   |\n",
      "| loss_q2   | 0.0034   |\n",
      "| loss_q3   | 0.00154  |\n",
      "| mse       | 0.0142   |\n",
      "| mse_q0    | 0.0525   |\n",
      "| mse_q1    | 0.0106   |\n",
      "| mse_q2    | 0.0034   |\n",
      "| mse_q3    | 0.00154  |\n",
      "| samples   | 3.2e+03  |\n",
      "| step      | 800      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.627    |\n",
      "| loss      | 0.0126   |\n",
      "| loss_q0   | 0.0456   |\n",
      "| loss_q1   | 0.0114   |\n",
      "| loss_q2   | 0.00346  |\n",
      "| loss_q3   | 0.0017   |\n",
      "| mse       | 0.0126   |\n",
      "| mse_q0    | 0.0456   |\n",
      "| mse_q1    | 0.0114   |\n",
      "| mse_q2    | 0.00346  |\n",
      "| mse_q3    | 0.0017   |\n",
      "| samples   | 3.24e+03 |\n",
      "| step      | 810      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.506    |\n",
      "| loss      | 0.0145   |\n",
      "| loss_q0   | 0.0431   |\n",
      "| loss_q1   | 0.0115   |\n",
      "| loss_q2   | 0.00313  |\n",
      "| loss_q3   | 0.00144  |\n",
      "| mse       | 0.0145   |\n",
      "| mse_q0    | 0.0431   |\n",
      "| mse_q1    | 0.0115   |\n",
      "| mse_q2    | 0.00313  |\n",
      "| mse_q3    | 0.00144  |\n",
      "| samples   | 3.28e+03 |\n",
      "| step      | 820      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.439    |\n",
      "| loss      | 0.0174   |\n",
      "| loss_q0   | 0.0549   |\n",
      "| loss_q1   | 0.00912  |\n",
      "| loss_q2   | 0.00334  |\n",
      "| loss_q3   | 0.0014   |\n",
      "| mse       | 0.0174   |\n",
      "| mse_q0    | 0.0549   |\n",
      "| mse_q1    | 0.00912  |\n",
      "| mse_q2    | 0.00334  |\n",
      "| mse_q3    | 0.0014   |\n",
      "| samples   | 3.32e+03 |\n",
      "| step      | 830      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.491    |\n",
      "| loss      | 0.0164   |\n",
      "| loss_q0   | 0.0509   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00295  |\n",
      "| loss_q3   | 0.00143  |\n",
      "| mse       | 0.0164   |\n",
      "| mse_q0    | 0.0509   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00295  |\n",
      "| mse_q3    | 0.00143  |\n",
      "| samples   | 3.36e+03 |\n",
      "| step      | 840      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.436    |\n",
      "| loss      | 0.0152   |\n",
      "| loss_q0   | 0.0403   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00362  |\n",
      "| loss_q3   | 0.00143  |\n",
      "| mse       | 0.0152   |\n",
      "| mse_q0    | 0.0403   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00362  |\n",
      "| mse_q3    | 0.00143  |\n",
      "| samples   | 3.4e+03  |\n",
      "| step      | 850      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.419    |\n",
      "| loss      | 0.015    |\n",
      "| loss_q0   | 0.0456   |\n",
      "| loss_q1   | 0.0112   |\n",
      "| loss_q2   | 0.00328  |\n",
      "| loss_q3   | 0.00145  |\n",
      "| mse       | 0.015    |\n",
      "| mse_q0    | 0.0456   |\n",
      "| mse_q1    | 0.0112   |\n",
      "| mse_q2    | 0.00328  |\n",
      "| mse_q3    | 0.00145  |\n",
      "| samples   | 3.44e+03 |\n",
      "| step      | 860      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.395    |\n",
      "| loss      | 0.013    |\n",
      "| loss_q0   | 0.0356   |\n",
      "| loss_q1   | 0.00985  |\n",
      "| loss_q2   | 0.00344  |\n",
      "| loss_q3   | 0.00141  |\n",
      "| mse       | 0.013    |\n",
      "| mse_q0    | 0.0356   |\n",
      "| mse_q1    | 0.00985  |\n",
      "| mse_q2    | 0.00344  |\n",
      "| mse_q3    | 0.00141  |\n",
      "| samples   | 3.48e+03 |\n",
      "| step      | 870      |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.421    |\n",
      "| loss      | 0.0128   |\n",
      "| loss_q0   | 0.0417   |\n",
      "| loss_q1   | 0.0094   |\n",
      "| loss_q2   | 0.00328  |\n",
      "| loss_q3   | 0.00139  |\n",
      "| mse       | 0.0128   |\n",
      "| mse_q0    | 0.0417   |\n",
      "| mse_q1    | 0.0094   |\n",
      "| mse_q2    | 0.00328  |\n",
      "| mse_q3    | 0.00139  |\n",
      "| samples   | 3.52e+03 |\n",
      "| step      | 880      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.412    |\n",
      "| loss      | 0.0133   |\n",
      "| loss_q0   | 0.0414   |\n",
      "| loss_q1   | 0.0103   |\n",
      "| loss_q2   | 0.00331  |\n",
      "| loss_q3   | 0.00139  |\n",
      "| mse       | 0.0133   |\n",
      "| mse_q0    | 0.0414   |\n",
      "| mse_q1    | 0.0103   |\n",
      "| mse_q2    | 0.00331  |\n",
      "| mse_q3    | 0.00139  |\n",
      "| samples   | 3.56e+03 |\n",
      "| step      | 890      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.469    |\n",
      "| loss      | 0.013    |\n",
      "| loss_q0   | 0.0345   |\n",
      "| loss_q1   | 0.0107   |\n",
      "| loss_q2   | 0.00277  |\n",
      "| loss_q3   | 0.0013   |\n",
      "| mse       | 0.013    |\n",
      "| mse_q0    | 0.0345   |\n",
      "| mse_q1    | 0.0107   |\n",
      "| mse_q2    | 0.00277  |\n",
      "| mse_q3    | 0.0013   |\n",
      "| samples   | 3.6e+03  |\n",
      "| step      | 900      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.436    |\n",
      "| loss      | 0.0131   |\n",
      "| loss_q0   | 0.0351   |\n",
      "| loss_q1   | 0.00972  |\n",
      "| loss_q2   | 0.00311  |\n",
      "| loss_q3   | 0.0014   |\n",
      "| mse       | 0.0131   |\n",
      "| mse_q0    | 0.0351   |\n",
      "| mse_q1    | 0.00972  |\n",
      "| mse_q2    | 0.00311  |\n",
      "| mse_q3    | 0.0014   |\n",
      "| samples   | 3.64e+03 |\n",
      "| step      | 910      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.466    |\n",
      "| loss      | 0.0132   |\n",
      "| loss_q0   | 0.0396   |\n",
      "| loss_q1   | 0.0093   |\n",
      "| loss_q2   | 0.00323  |\n",
      "| loss_q3   | 0.00135  |\n",
      "| mse       | 0.0132   |\n",
      "| mse_q0    | 0.0396   |\n",
      "| mse_q1    | 0.0093   |\n",
      "| mse_q2    | 0.00323  |\n",
      "| mse_q3    | 0.00135  |\n",
      "| samples   | 3.68e+03 |\n",
      "| step      | 920      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.509    |\n",
      "| loss      | 0.0124   |\n",
      "| loss_q0   | 0.0404   |\n",
      "| loss_q1   | 0.0105   |\n",
      "| loss_q2   | 0.0034   |\n",
      "| loss_q3   | 0.00134  |\n",
      "| mse       | 0.0124   |\n",
      "| mse_q0    | 0.0404   |\n",
      "| mse_q1    | 0.0105   |\n",
      "| mse_q2    | 0.0034   |\n",
      "| mse_q3    | 0.00134  |\n",
      "| samples   | 3.72e+03 |\n",
      "| step      | 930      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.639    |\n",
      "| loss      | 0.02     |\n",
      "| loss_q0   | 0.0587   |\n",
      "| loss_q1   | 0.0108   |\n",
      "| loss_q2   | 0.00328  |\n",
      "| loss_q3   | 0.00156  |\n",
      "| mse       | 0.02     |\n",
      "| mse_q0    | 0.0587   |\n",
      "| mse_q1    | 0.0108   |\n",
      "| mse_q2    | 0.00328  |\n",
      "| mse_q3    | 0.00156  |\n",
      "| samples   | 3.76e+03 |\n",
      "| step      | 940      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.509    |\n",
      "| loss      | 0.0147   |\n",
      "| loss_q0   | 0.0444   |\n",
      "| loss_q1   | 0.0113   |\n",
      "| loss_q2   | 0.0031   |\n",
      "| loss_q3   | 0.00174  |\n",
      "| mse       | 0.0147   |\n",
      "| mse_q0    | 0.0444   |\n",
      "| mse_q1    | 0.0113   |\n",
      "| mse_q2    | 0.0031   |\n",
      "| mse_q3    | 0.00174  |\n",
      "| samples   | 3.8e+03  |\n",
      "| step      | 950      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.532    |\n",
      "| loss      | 0.0158   |\n",
      "| loss_q0   | 0.0491   |\n",
      "| loss_q1   | 0.0101   |\n",
      "| loss_q2   | 0.00342  |\n",
      "| loss_q3   | 0.00146  |\n",
      "| mse       | 0.0158   |\n",
      "| mse_q0    | 0.0491   |\n",
      "| mse_q1    | 0.0101   |\n",
      "| mse_q2    | 0.00342  |\n",
      "| mse_q3    | 0.00146  |\n",
      "| samples   | 3.84e+03 |\n",
      "| step      | 960      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.47     |\n",
      "| loss      | 0.0143   |\n",
      "| loss_q0   | 0.0442   |\n",
      "| loss_q1   | 0.0105   |\n",
      "| loss_q2   | 0.00309  |\n",
      "| loss_q3   | 0.0014   |\n",
      "| mse       | 0.0143   |\n",
      "| mse_q0    | 0.0442   |\n",
      "| mse_q1    | 0.0105   |\n",
      "| mse_q2    | 0.00309  |\n",
      "| mse_q3    | 0.0014   |\n",
      "| samples   | 3.88e+03 |\n",
      "| step      | 970      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.438    |\n",
      "| loss      | 0.0149   |\n",
      "| loss_q0   | 0.0472   |\n",
      "| loss_q1   | 0.0083   |\n",
      "| loss_q2   | 0.00329  |\n",
      "| loss_q3   | 0.00128  |\n",
      "| mse       | 0.0149   |\n",
      "| mse_q0    | 0.0472   |\n",
      "| mse_q1    | 0.0083   |\n",
      "| mse_q2    | 0.00329  |\n",
      "| mse_q3    | 0.00128  |\n",
      "| samples   | 3.92e+03 |\n",
      "| step      | 980      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.576    |\n",
      "| loss      | 0.0194   |\n",
      "| loss_q0   | 0.0636   |\n",
      "| loss_q1   | 0.0101   |\n",
      "| loss_q2   | 0.00304  |\n",
      "| loss_q3   | 0.00136  |\n",
      "| mse       | 0.0194   |\n",
      "| mse_q0    | 0.0636   |\n",
      "| mse_q1    | 0.0101   |\n",
      "| mse_q2    | 0.00304  |\n",
      "| mse_q3    | 0.00136  |\n",
      "| samples   | 3.96e+03 |\n",
      "| step      | 990      |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.62     |\n",
      "| loss      | 0.0138   |\n",
      "| loss_q0   | 0.0374   |\n",
      "| loss_q1   | 0.0109   |\n",
      "| loss_q2   | 0.00337  |\n",
      "| loss_q3   | 0.00147  |\n",
      "| mse       | 0.0138   |\n",
      "| mse_q0    | 0.0374   |\n",
      "| mse_q1    | 0.0109   |\n",
      "| mse_q2    | 0.00337  |\n",
      "| mse_q3    | 0.00147  |\n",
      "| samples   | 4e+03    |\n",
      "| step      | 1e+03    |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.771    |\n",
      "| loss      | 0.0136   |\n",
      "| loss_q0   | 0.0491   |\n",
      "| loss_q1   | 0.0104   |\n",
      "| loss_q2   | 0.0028   |\n",
      "| loss_q3   | 0.00156  |\n",
      "| mse       | 0.0136   |\n",
      "| mse_q0    | 0.0491   |\n",
      "| mse_q1    | 0.0104   |\n",
      "| mse_q2    | 0.0028   |\n",
      "| mse_q3    | 0.00156  |\n",
      "| samples   | 4.04e+03 |\n",
      "| step      | 1.01e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.756    |\n",
      "| loss      | 0.014    |\n",
      "| loss_q0   | 0.0509   |\n",
      "| loss_q1   | 0.00927  |\n",
      "| loss_q2   | 0.00297  |\n",
      "| loss_q3   | 0.00159  |\n",
      "| mse       | 0.014    |\n",
      "| mse_q0    | 0.0509   |\n",
      "| mse_q1    | 0.00927  |\n",
      "| mse_q2    | 0.00297  |\n",
      "| mse_q3    | 0.00159  |\n",
      "| samples   | 4.08e+03 |\n",
      "| step      | 1.02e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.525    |\n",
      "| loss      | 0.0119   |\n",
      "| loss_q0   | 0.0414   |\n",
      "| loss_q1   | 0.0104   |\n",
      "| loss_q2   | 0.00284  |\n",
      "| loss_q3   | 0.00138  |\n",
      "| mse       | 0.0119   |\n",
      "| mse_q0    | 0.0414   |\n",
      "| mse_q1    | 0.0104   |\n",
      "| mse_q2    | 0.00284  |\n",
      "| mse_q3    | 0.00138  |\n",
      "| samples   | 4.12e+03 |\n",
      "| step      | 1.03e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.52     |\n",
      "| loss      | 0.0151   |\n",
      "| loss_q0   | 0.0417   |\n",
      "| loss_q1   | 0.00986  |\n",
      "| loss_q2   | 0.00302  |\n",
      "| loss_q3   | 0.00126  |\n",
      "| mse       | 0.0151   |\n",
      "| mse_q0    | 0.0417   |\n",
      "| mse_q1    | 0.00986  |\n",
      "| mse_q2    | 0.00302  |\n",
      "| mse_q3    | 0.00126  |\n",
      "| samples   | 4.16e+03 |\n",
      "| step      | 1.04e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.476    |\n",
      "| loss      | 0.0148   |\n",
      "| loss_q0   | 0.0395   |\n",
      "| loss_q1   | 0.00997  |\n",
      "| loss_q2   | 0.00319  |\n",
      "| loss_q3   | 0.00133  |\n",
      "| mse       | 0.0148   |\n",
      "| mse_q0    | 0.0395   |\n",
      "| mse_q1    | 0.00997  |\n",
      "| mse_q2    | 0.00319  |\n",
      "| mse_q3    | 0.00133  |\n",
      "| samples   | 4.2e+03  |\n",
      "| step      | 1.05e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.481    |\n",
      "| loss      | 0.0146   |\n",
      "| loss_q0   | 0.0405   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00292  |\n",
      "| loss_q3   | 0.00128  |\n",
      "| mse       | 0.0146   |\n",
      "| mse_q0    | 0.0405   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00292  |\n",
      "| mse_q3    | 0.00128  |\n",
      "| samples   | 4.24e+03 |\n",
      "| step      | 1.06e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.467    |\n",
      "| loss      | 0.0152   |\n",
      "| loss_q0   | 0.0503   |\n",
      "| loss_q1   | 0.00911  |\n",
      "| loss_q2   | 0.00287  |\n",
      "| loss_q3   | 0.00126  |\n",
      "| mse       | 0.0152   |\n",
      "| mse_q0    | 0.0503   |\n",
      "| mse_q1    | 0.00911  |\n",
      "| mse_q2    | 0.00287  |\n",
      "| mse_q3    | 0.00126  |\n",
      "| samples   | 4.28e+03 |\n",
      "| step      | 1.07e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.415    |\n",
      "| loss      | 0.0149   |\n",
      "| loss_q0   | 0.0446   |\n",
      "| loss_q1   | 0.01     |\n",
      "| loss_q2   | 0.00281  |\n",
      "| loss_q3   | 0.00125  |\n",
      "| mse       | 0.0149   |\n",
      "| mse_q0    | 0.0446   |\n",
      "| mse_q1    | 0.01     |\n",
      "| mse_q2    | 0.00281  |\n",
      "| mse_q3    | 0.00125  |\n",
      "| samples   | 4.32e+03 |\n",
      "| step      | 1.08e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.518    |\n",
      "| loss      | 0.012    |\n",
      "| loss_q0   | 0.034    |\n",
      "| loss_q1   | 0.00985  |\n",
      "| loss_q2   | 0.00289  |\n",
      "| loss_q3   | 0.00145  |\n",
      "| mse       | 0.012    |\n",
      "| mse_q0    | 0.034    |\n",
      "| mse_q1    | 0.00985  |\n",
      "| mse_q2    | 0.00289  |\n",
      "| mse_q3    | 0.00145  |\n",
      "| samples   | 4.36e+03 |\n",
      "| step      | 1.09e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.636    |\n",
      "| loss      | 0.0165   |\n",
      "| loss_q0   | 0.0484   |\n",
      "| loss_q1   | 0.0107   |\n",
      "| loss_q2   | 0.00318  |\n",
      "| loss_q3   | 0.0014   |\n",
      "| mse       | 0.0165   |\n",
      "| mse_q0    | 0.0484   |\n",
      "| mse_q1    | 0.0107   |\n",
      "| mse_q2    | 0.00318  |\n",
      "| mse_q3    | 0.0014   |\n",
      "| samples   | 4.4e+03  |\n",
      "| step      | 1.1e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.703    |\n",
      "| loss      | 0.0219   |\n",
      "| loss_q0   | 0.0606   |\n",
      "| loss_q1   | 0.0101   |\n",
      "| loss_q2   | 0.00277  |\n",
      "| loss_q3   | 0.00128  |\n",
      "| mse       | 0.0219   |\n",
      "| mse_q0    | 0.0606   |\n",
      "| mse_q1    | 0.0101   |\n",
      "| mse_q2    | 0.00277  |\n",
      "| mse_q3    | 0.00128  |\n",
      "| samples   | 4.44e+03 |\n",
      "| step      | 1.11e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.396    |\n",
      "| loss      | 0.0139   |\n",
      "| loss_q0   | 0.0394   |\n",
      "| loss_q1   | 0.0095   |\n",
      "| loss_q2   | 0.00305  |\n",
      "| loss_q3   | 0.00127  |\n",
      "| mse       | 0.0139   |\n",
      "| mse_q0    | 0.0394   |\n",
      "| mse_q1    | 0.0095   |\n",
      "| mse_q2    | 0.00305  |\n",
      "| mse_q3    | 0.00127  |\n",
      "| samples   | 4.48e+03 |\n",
      "| step      | 1.12e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.345    |\n",
      "| loss      | 0.0138   |\n",
      "| loss_q0   | 0.0396   |\n",
      "| loss_q1   | 0.00952  |\n",
      "| loss_q2   | 0.00325  |\n",
      "| loss_q3   | 0.00123  |\n",
      "| mse       | 0.0138   |\n",
      "| mse_q0    | 0.0396   |\n",
      "| mse_q1    | 0.00952  |\n",
      "| mse_q2    | 0.00325  |\n",
      "| mse_q3    | 0.00123  |\n",
      "| samples   | 4.52e+03 |\n",
      "| step      | 1.13e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.461    |\n",
      "| loss      | 0.015    |\n",
      "| loss_q0   | 0.0459   |\n",
      "| loss_q1   | 0.0106   |\n",
      "| loss_q2   | 0.00289  |\n",
      "| loss_q3   | 0.00122  |\n",
      "| mse       | 0.015    |\n",
      "| mse_q0    | 0.0459   |\n",
      "| mse_q1    | 0.0106   |\n",
      "| mse_q2    | 0.00289  |\n",
      "| mse_q3    | 0.00122  |\n",
      "| samples   | 4.56e+03 |\n",
      "| step      | 1.14e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.49     |\n",
      "| loss      | 0.0143   |\n",
      "| loss_q0   | 0.0449   |\n",
      "| loss_q1   | 0.00936  |\n",
      "| loss_q2   | 0.00309  |\n",
      "| loss_q3   | 0.00124  |\n",
      "| mse       | 0.0143   |\n",
      "| mse_q0    | 0.0449   |\n",
      "| mse_q1    | 0.00936  |\n",
      "| mse_q2    | 0.00309  |\n",
      "| mse_q3    | 0.00124  |\n",
      "| samples   | 4.6e+03  |\n",
      "| step      | 1.15e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.532    |\n",
      "| loss      | 0.0137   |\n",
      "| loss_q0   | 0.0383   |\n",
      "| loss_q1   | 0.00895  |\n",
      "| loss_q2   | 0.00303  |\n",
      "| loss_q3   | 0.0012   |\n",
      "| mse       | 0.0137   |\n",
      "| mse_q0    | 0.0383   |\n",
      "| mse_q1    | 0.00895  |\n",
      "| mse_q2    | 0.00303  |\n",
      "| mse_q3    | 0.0012   |\n",
      "| samples   | 4.64e+03 |\n",
      "| step      | 1.16e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.424    |\n",
      "| loss      | 0.0142   |\n",
      "| loss_q0   | 0.0436   |\n",
      "| loss_q1   | 0.00948  |\n",
      "| loss_q2   | 0.00287  |\n",
      "| loss_q3   | 0.00116  |\n",
      "| mse       | 0.0142   |\n",
      "| mse_q0    | 0.0436   |\n",
      "| mse_q1    | 0.00948  |\n",
      "| mse_q2    | 0.00287  |\n",
      "| mse_q3    | 0.00116  |\n",
      "| samples   | 4.68e+03 |\n",
      "| step      | 1.17e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.455    |\n",
      "| loss      | 0.0159   |\n",
      "| loss_q0   | 0.0445   |\n",
      "| loss_q1   | 0.00937  |\n",
      "| loss_q2   | 0.00306  |\n",
      "| loss_q3   | 0.00111  |\n",
      "| mse       | 0.0159   |\n",
      "| mse_q0    | 0.0445   |\n",
      "| mse_q1    | 0.00937  |\n",
      "| mse_q2    | 0.00306  |\n",
      "| mse_q3    | 0.00111  |\n",
      "| samples   | 4.72e+03 |\n",
      "| step      | 1.18e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.464    |\n",
      "| loss      | 0.015    |\n",
      "| loss_q0   | 0.0433   |\n",
      "| loss_q1   | 0.00962  |\n",
      "| loss_q2   | 0.00342  |\n",
      "| loss_q3   | 0.00115  |\n",
      "| mse       | 0.015    |\n",
      "| mse_q0    | 0.0433   |\n",
      "| mse_q1    | 0.00962  |\n",
      "| mse_q2    | 0.00342  |\n",
      "| mse_q3    | 0.00115  |\n",
      "| samples   | 4.76e+03 |\n",
      "| step      | 1.19e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.386    |\n",
      "| loss      | 0.00976  |\n",
      "| loss_q0   | 0.0319   |\n",
      "| loss_q1   | 0.00934  |\n",
      "| loss_q2   | 0.00271  |\n",
      "| loss_q3   | 0.00111  |\n",
      "| mse       | 0.00976  |\n",
      "| mse_q0    | 0.0319   |\n",
      "| mse_q1    | 0.00934  |\n",
      "| mse_q2    | 0.00271  |\n",
      "| mse_q3    | 0.00111  |\n",
      "| samples   | 4.8e+03  |\n",
      "| step      | 1.2e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.348    |\n",
      "| loss      | 0.013    |\n",
      "| loss_q0   | 0.0375   |\n",
      "| loss_q1   | 0.0101   |\n",
      "| loss_q2   | 0.00277  |\n",
      "| loss_q3   | 0.00107  |\n",
      "| mse       | 0.013    |\n",
      "| mse_q0    | 0.0375   |\n",
      "| mse_q1    | 0.0101   |\n",
      "| mse_q2    | 0.00277  |\n",
      "| mse_q3    | 0.00107  |\n",
      "| samples   | 4.84e+03 |\n",
      "| step      | 1.21e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.423    |\n",
      "| loss      | 0.0158   |\n",
      "| loss_q0   | 0.0437   |\n",
      "| loss_q1   | 0.0095   |\n",
      "| loss_q2   | 0.00299  |\n",
      "| loss_q3   | 0.00118  |\n",
      "| mse       | 0.0158   |\n",
      "| mse_q0    | 0.0437   |\n",
      "| mse_q1    | 0.0095   |\n",
      "| mse_q2    | 0.00299  |\n",
      "| mse_q3    | 0.00118  |\n",
      "| samples   | 4.88e+03 |\n",
      "| step      | 1.22e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.453    |\n",
      "| loss      | 0.0111   |\n",
      "| loss_q0   | 0.0383   |\n",
      "| loss_q1   | 0.00957  |\n",
      "| loss_q2   | 0.00303  |\n",
      "| loss_q3   | 0.00114  |\n",
      "| mse       | 0.0111   |\n",
      "| mse_q0    | 0.0383   |\n",
      "| mse_q1    | 0.00957  |\n",
      "| mse_q2    | 0.00303  |\n",
      "| mse_q3    | 0.00114  |\n",
      "| samples   | 4.92e+03 |\n",
      "| step      | 1.23e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.497    |\n",
      "| loss      | 0.0149   |\n",
      "| loss_q0   | 0.0409   |\n",
      "| loss_q1   | 0.0101   |\n",
      "| loss_q2   | 0.00334  |\n",
      "| loss_q3   | 0.00121  |\n",
      "| mse       | 0.0149   |\n",
      "| mse_q0    | 0.0409   |\n",
      "| mse_q1    | 0.0101   |\n",
      "| mse_q2    | 0.00334  |\n",
      "| mse_q3    | 0.00121  |\n",
      "| samples   | 4.96e+03 |\n",
      "| step      | 1.24e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.449    |\n",
      "| loss      | 0.0128   |\n",
      "| loss_q0   | 0.0381   |\n",
      "| loss_q1   | 0.00916  |\n",
      "| loss_q2   | 0.00281  |\n",
      "| loss_q3   | 0.00107  |\n",
      "| mse       | 0.0128   |\n",
      "| mse_q0    | 0.0381   |\n",
      "| mse_q1    | 0.00916  |\n",
      "| mse_q2    | 0.00281  |\n",
      "| mse_q3    | 0.00107  |\n",
      "| samples   | 5e+03    |\n",
      "| step      | 1.25e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.371    |\n",
      "| loss      | 0.0124   |\n",
      "| loss_q0   | 0.0379   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00298  |\n",
      "| loss_q3   | 0.00116  |\n",
      "| mse       | 0.0124   |\n",
      "| mse_q0    | 0.0379   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00298  |\n",
      "| mse_q3    | 0.00116  |\n",
      "| samples   | 5.04e+03 |\n",
      "| step      | 1.26e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.526    |\n",
      "| loss      | 0.0139   |\n",
      "| loss_q0   | 0.0383   |\n",
      "| loss_q1   | 0.00989  |\n",
      "| loss_q2   | 0.00313  |\n",
      "| loss_q3   | 0.0011   |\n",
      "| mse       | 0.0139   |\n",
      "| mse_q0    | 0.0383   |\n",
      "| mse_q1    | 0.00989  |\n",
      "| mse_q2    | 0.00313  |\n",
      "| mse_q3    | 0.0011   |\n",
      "| samples   | 5.08e+03 |\n",
      "| step      | 1.27e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.516    |\n",
      "| loss      | 0.0138   |\n",
      "| loss_q0   | 0.0353   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00279  |\n",
      "| loss_q3   | 0.00116  |\n",
      "| mse       | 0.0138   |\n",
      "| mse_q0    | 0.0353   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00279  |\n",
      "| mse_q3    | 0.00116  |\n",
      "| samples   | 5.12e+03 |\n",
      "| step      | 1.28e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.503    |\n",
      "| loss      | 0.0157   |\n",
      "| loss_q0   | 0.0423   |\n",
      "| loss_q1   | 0.0097   |\n",
      "| loss_q2   | 0.00281  |\n",
      "| loss_q3   | 0.00115  |\n",
      "| mse       | 0.0157   |\n",
      "| mse_q0    | 0.0423   |\n",
      "| mse_q1    | 0.0097   |\n",
      "| mse_q2    | 0.00281  |\n",
      "| mse_q3    | 0.00115  |\n",
      "| samples   | 5.16e+03 |\n",
      "| step      | 1.29e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.538    |\n",
      "| loss      | 0.0117   |\n",
      "| loss_q0   | 0.0301   |\n",
      "| loss_q1   | 0.00965  |\n",
      "| loss_q2   | 0.0028   |\n",
      "| loss_q3   | 0.00119  |\n",
      "| mse       | 0.0117   |\n",
      "| mse_q0    | 0.0301   |\n",
      "| mse_q1    | 0.00965  |\n",
      "| mse_q2    | 0.0028   |\n",
      "| mse_q3    | 0.00119  |\n",
      "| samples   | 5.2e+03  |\n",
      "| step      | 1.3e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.483    |\n",
      "| loss      | 0.0148   |\n",
      "| loss_q0   | 0.0471   |\n",
      "| loss_q1   | 0.00914  |\n",
      "| loss_q2   | 0.00318  |\n",
      "| loss_q3   | 0.00111  |\n",
      "| mse       | 0.0148   |\n",
      "| mse_q0    | 0.0471   |\n",
      "| mse_q1    | 0.00914  |\n",
      "| mse_q2    | 0.00318  |\n",
      "| mse_q3    | 0.00111  |\n",
      "| samples   | 5.24e+03 |\n",
      "| step      | 1.31e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.562    |\n",
      "| loss      | 0.0169   |\n",
      "| loss_q0   | 0.048    |\n",
      "| loss_q1   | 0.01     |\n",
      "| loss_q2   | 0.00318  |\n",
      "| loss_q3   | 0.00116  |\n",
      "| mse       | 0.0169   |\n",
      "| mse_q0    | 0.048    |\n",
      "| mse_q1    | 0.01     |\n",
      "| mse_q2    | 0.00318  |\n",
      "| mse_q3    | 0.00116  |\n",
      "| samples   | 5.28e+03 |\n",
      "| step      | 1.32e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.592    |\n",
      "| loss      | 0.0129   |\n",
      "| loss_q0   | 0.0359   |\n",
      "| loss_q1   | 0.00971  |\n",
      "| loss_q2   | 0.00272  |\n",
      "| loss_q3   | 0.00123  |\n",
      "| mse       | 0.0129   |\n",
      "| mse_q0    | 0.0359   |\n",
      "| mse_q1    | 0.00971  |\n",
      "| mse_q2    | 0.00272  |\n",
      "| mse_q3    | 0.00123  |\n",
      "| samples   | 5.32e+03 |\n",
      "| step      | 1.33e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.499    |\n",
      "| loss      | 0.0171   |\n",
      "| loss_q0   | 0.0519   |\n",
      "| loss_q1   | 0.0106   |\n",
      "| loss_q2   | 0.00282  |\n",
      "| loss_q3   | 0.00117  |\n",
      "| mse       | 0.0171   |\n",
      "| mse_q0    | 0.0519   |\n",
      "| mse_q1    | 0.0106   |\n",
      "| mse_q2    | 0.00282  |\n",
      "| mse_q3    | 0.00117  |\n",
      "| samples   | 5.36e+03 |\n",
      "| step      | 1.34e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.472    |\n",
      "| loss      | 0.0132   |\n",
      "| loss_q0   | 0.0405   |\n",
      "| loss_q1   | 0.00933  |\n",
      "| loss_q2   | 0.00279  |\n",
      "| loss_q3   | 0.0011   |\n",
      "| mse       | 0.0132   |\n",
      "| mse_q0    | 0.0405   |\n",
      "| mse_q1    | 0.00933  |\n",
      "| mse_q2    | 0.00279  |\n",
      "| mse_q3    | 0.0011   |\n",
      "| samples   | 5.4e+03  |\n",
      "| step      | 1.35e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.511    |\n",
      "| loss      | 0.0124   |\n",
      "| loss_q0   | 0.0306   |\n",
      "| loss_q1   | 0.00977  |\n",
      "| loss_q2   | 0.00269  |\n",
      "| loss_q3   | 0.00117  |\n",
      "| mse       | 0.0124   |\n",
      "| mse_q0    | 0.0306   |\n",
      "| mse_q1    | 0.00977  |\n",
      "| mse_q2    | 0.00269  |\n",
      "| mse_q3    | 0.00117  |\n",
      "| samples   | 5.44e+03 |\n",
      "| step      | 1.36e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.404    |\n",
      "| loss      | 0.0121   |\n",
      "| loss_q0   | 0.0389   |\n",
      "| loss_q1   | 0.0097   |\n",
      "| loss_q2   | 0.00284  |\n",
      "| loss_q3   | 0.00113  |\n",
      "| mse       | 0.0121   |\n",
      "| mse_q0    | 0.0389   |\n",
      "| mse_q1    | 0.0097   |\n",
      "| mse_q2    | 0.00284  |\n",
      "| mse_q3    | 0.00113  |\n",
      "| samples   | 5.48e+03 |\n",
      "| step      | 1.37e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.358    |\n",
      "| loss      | 0.0123   |\n",
      "| loss_q0   | 0.0378   |\n",
      "| loss_q1   | 0.00992  |\n",
      "| loss_q2   | 0.00282  |\n",
      "| loss_q3   | 0.00105  |\n",
      "| mse       | 0.0123   |\n",
      "| mse_q0    | 0.0378   |\n",
      "| mse_q1    | 0.00992  |\n",
      "| mse_q2    | 0.00282  |\n",
      "| mse_q3    | 0.00105  |\n",
      "| samples   | 5.52e+03 |\n",
      "| step      | 1.38e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.371    |\n",
      "| loss      | 0.0104   |\n",
      "| loss_q0   | 0.0312   |\n",
      "| loss_q1   | 0.00984  |\n",
      "| loss_q2   | 0.00281  |\n",
      "| loss_q3   | 0.00104  |\n",
      "| mse       | 0.0104   |\n",
      "| mse_q0    | 0.0312   |\n",
      "| mse_q1    | 0.00984  |\n",
      "| mse_q2    | 0.00281  |\n",
      "| mse_q3    | 0.00104  |\n",
      "| samples   | 5.56e+03 |\n",
      "| step      | 1.39e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.406    |\n",
      "| loss      | 0.0127   |\n",
      "| loss_q0   | 0.0353   |\n",
      "| loss_q1   | 0.00892  |\n",
      "| loss_q2   | 0.00262  |\n",
      "| loss_q3   | 0.00109  |\n",
      "| mse       | 0.0127   |\n",
      "| mse_q0    | 0.0353   |\n",
      "| mse_q1    | 0.00892  |\n",
      "| mse_q2    | 0.00262  |\n",
      "| mse_q3    | 0.00109  |\n",
      "| samples   | 5.6e+03  |\n",
      "| step      | 1.4e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.487    |\n",
      "| loss      | 0.0131   |\n",
      "| loss_q0   | 0.041    |\n",
      "| loss_q1   | 0.0103   |\n",
      "| loss_q2   | 0.00299  |\n",
      "| loss_q3   | 0.00108  |\n",
      "| mse       | 0.0131   |\n",
      "| mse_q0    | 0.041    |\n",
      "| mse_q1    | 0.0103   |\n",
      "| mse_q2    | 0.00299  |\n",
      "| mse_q3    | 0.00108  |\n",
      "| samples   | 5.64e+03 |\n",
      "| step      | 1.41e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.494    |\n",
      "| loss      | 0.0125   |\n",
      "| loss_q0   | 0.0351   |\n",
      "| loss_q1   | 0.00998  |\n",
      "| loss_q2   | 0.00268  |\n",
      "| loss_q3   | 0.00116  |\n",
      "| mse       | 0.0125   |\n",
      "| mse_q0    | 0.0351   |\n",
      "| mse_q1    | 0.00998  |\n",
      "| mse_q2    | 0.00268  |\n",
      "| mse_q3    | 0.00116  |\n",
      "| samples   | 5.68e+03 |\n",
      "| step      | 1.42e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.477    |\n",
      "| loss      | 0.0106   |\n",
      "| loss_q0   | 0.0359   |\n",
      "| loss_q1   | 0.0088   |\n",
      "| loss_q2   | 0.00294  |\n",
      "| loss_q3   | 0.00106  |\n",
      "| mse       | 0.0106   |\n",
      "| mse_q0    | 0.0359   |\n",
      "| mse_q1    | 0.0088   |\n",
      "| mse_q2    | 0.00294  |\n",
      "| mse_q3    | 0.00106  |\n",
      "| samples   | 5.72e+03 |\n",
      "| step      | 1.43e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.51     |\n",
      "| loss      | 0.0113   |\n",
      "| loss_q0   | 0.0295   |\n",
      "| loss_q1   | 0.0103   |\n",
      "| loss_q2   | 0.0027   |\n",
      "| loss_q3   | 0.00102  |\n",
      "| mse       | 0.0113   |\n",
      "| mse_q0    | 0.0295   |\n",
      "| mse_q1    | 0.0103   |\n",
      "| mse_q2    | 0.0027   |\n",
      "| mse_q3    | 0.00102  |\n",
      "| samples   | 5.76e+03 |\n",
      "| step      | 1.44e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.524    |\n",
      "| loss      | 0.0102   |\n",
      "| loss_q0   | 0.0351   |\n",
      "| loss_q1   | 0.00984  |\n",
      "| loss_q2   | 0.00288  |\n",
      "| loss_q3   | 0.00105  |\n",
      "| mse       | 0.0102   |\n",
      "| mse_q0    | 0.0351   |\n",
      "| mse_q1    | 0.00984  |\n",
      "| mse_q2    | 0.00288  |\n",
      "| mse_q3    | 0.00105  |\n",
      "| samples   | 5.8e+03  |\n",
      "| step      | 1.45e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.493    |\n",
      "| loss      | 0.0176   |\n",
      "| loss_q0   | 0.0489   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00282  |\n",
      "| loss_q3   | 0.00104  |\n",
      "| mse       | 0.0176   |\n",
      "| mse_q0    | 0.0489   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00282  |\n",
      "| mse_q3    | 0.00104  |\n",
      "| samples   | 5.84e+03 |\n",
      "| step      | 1.46e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.71     |\n",
      "| loss      | 0.0143   |\n",
      "| loss_q0   | 0.0437   |\n",
      "| loss_q1   | 0.00993  |\n",
      "| loss_q2   | 0.00265  |\n",
      "| loss_q3   | 0.00122  |\n",
      "| mse       | 0.0143   |\n",
      "| mse_q0    | 0.0437   |\n",
      "| mse_q1    | 0.00993  |\n",
      "| mse_q2    | 0.00265  |\n",
      "| mse_q3    | 0.00122  |\n",
      "| samples   | 5.88e+03 |\n",
      "| step      | 1.47e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.733    |\n",
      "| loss      | 0.0164   |\n",
      "| loss_q0   | 0.0417   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00339  |\n",
      "| loss_q3   | 0.00149  |\n",
      "| mse       | 0.0164   |\n",
      "| mse_q0    | 0.0417   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00339  |\n",
      "| mse_q3    | 0.00149  |\n",
      "| samples   | 5.92e+03 |\n",
      "| step      | 1.48e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.534    |\n",
      "| loss      | 0.0133   |\n",
      "| loss_q0   | 0.0412   |\n",
      "| loss_q1   | 0.00984  |\n",
      "| loss_q2   | 0.00333  |\n",
      "| loss_q3   | 0.00141  |\n",
      "| mse       | 0.0133   |\n",
      "| mse_q0    | 0.0412   |\n",
      "| mse_q1    | 0.00984  |\n",
      "| mse_q2    | 0.00333  |\n",
      "| mse_q3    | 0.00141  |\n",
      "| samples   | 5.96e+03 |\n",
      "| step      | 1.49e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.397    |\n",
      "| loss      | 0.0129   |\n",
      "| loss_q0   | 0.0367   |\n",
      "| loss_q1   | 0.0106   |\n",
      "| loss_q2   | 0.00326  |\n",
      "| loss_q3   | 0.00107  |\n",
      "| mse       | 0.0129   |\n",
      "| mse_q0    | 0.0367   |\n",
      "| mse_q1    | 0.0106   |\n",
      "| mse_q2    | 0.00326  |\n",
      "| mse_q3    | 0.00107  |\n",
      "| samples   | 6e+03    |\n",
      "| step      | 1.5e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.484    |\n",
      "| loss      | 0.0167   |\n",
      "| loss_q0   | 0.0455   |\n",
      "| loss_q1   | 0.00938  |\n",
      "| loss_q2   | 0.00314  |\n",
      "| loss_q3   | 0.00105  |\n",
      "| mse       | 0.0167   |\n",
      "| mse_q0    | 0.0455   |\n",
      "| mse_q1    | 0.00938  |\n",
      "| mse_q2    | 0.00314  |\n",
      "| mse_q3    | 0.00105  |\n",
      "| samples   | 6.04e+03 |\n",
      "| step      | 1.51e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.439    |\n",
      "| loss      | 0.0142   |\n",
      "| loss_q0   | 0.0433   |\n",
      "| loss_q1   | 0.00959  |\n",
      "| loss_q2   | 0.00266  |\n",
      "| loss_q3   | 0.00116  |\n",
      "| mse       | 0.0142   |\n",
      "| mse_q0    | 0.0433   |\n",
      "| mse_q1    | 0.00959  |\n",
      "| mse_q2    | 0.00266  |\n",
      "| mse_q3    | 0.00116  |\n",
      "| samples   | 6.08e+03 |\n",
      "| step      | 1.52e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.414    |\n",
      "| loss      | 0.0125   |\n",
      "| loss_q0   | 0.0345   |\n",
      "| loss_q1   | 0.0106   |\n",
      "| loss_q2   | 0.00267  |\n",
      "| loss_q3   | 0.00109  |\n",
      "| mse       | 0.0125   |\n",
      "| mse_q0    | 0.0345   |\n",
      "| mse_q1    | 0.0106   |\n",
      "| mse_q2    | 0.00267  |\n",
      "| mse_q3    | 0.00109  |\n",
      "| samples   | 6.12e+03 |\n",
      "| step      | 1.53e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.588    |\n",
      "| loss      | 0.0221   |\n",
      "| loss_q0   | 0.0683   |\n",
      "| loss_q1   | 0.0097   |\n",
      "| loss_q2   | 0.00284  |\n",
      "| loss_q3   | 0.00102  |\n",
      "| mse       | 0.0221   |\n",
      "| mse_q0    | 0.0683   |\n",
      "| mse_q1    | 0.0097   |\n",
      "| mse_q2    | 0.00284  |\n",
      "| mse_q3    | 0.00102  |\n",
      "| samples   | 6.16e+03 |\n",
      "| step      | 1.54e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.505    |\n",
      "| loss      | 0.0142   |\n",
      "| loss_q0   | 0.0428   |\n",
      "| loss_q1   | 0.00969  |\n",
      "| loss_q2   | 0.00258  |\n",
      "| loss_q3   | 0.00118  |\n",
      "| mse       | 0.0142   |\n",
      "| mse_q0    | 0.0428   |\n",
      "| mse_q1    | 0.00969  |\n",
      "| mse_q2    | 0.00258  |\n",
      "| mse_q3    | 0.00118  |\n",
      "| samples   | 6.2e+03  |\n",
      "| step      | 1.55e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.486    |\n",
      "| loss      | 0.0166   |\n",
      "| loss_q0   | 0.04     |\n",
      "| loss_q1   | 0.00964  |\n",
      "| loss_q2   | 0.00328  |\n",
      "| loss_q3   | 0.00121  |\n",
      "| mse       | 0.0166   |\n",
      "| mse_q0    | 0.04     |\n",
      "| mse_q1    | 0.00964  |\n",
      "| mse_q2    | 0.00328  |\n",
      "| mse_q3    | 0.00121  |\n",
      "| samples   | 6.24e+03 |\n",
      "| step      | 1.56e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.358    |\n",
      "| loss      | 0.0113   |\n",
      "| loss_q0   | 0.0435   |\n",
      "| loss_q1   | 0.00912  |\n",
      "| loss_q2   | 0.0026   |\n",
      "| loss_q3   | 0.00107  |\n",
      "| mse       | 0.0113   |\n",
      "| mse_q0    | 0.0435   |\n",
      "| mse_q1    | 0.00912  |\n",
      "| mse_q2    | 0.0026   |\n",
      "| mse_q3    | 0.00107  |\n",
      "| samples   | 6.28e+03 |\n",
      "| step      | 1.57e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.396    |\n",
      "| loss      | 0.0154   |\n",
      "| loss_q0   | 0.036    |\n",
      "| loss_q1   | 0.0097   |\n",
      "| loss_q2   | 0.0023   |\n",
      "| loss_q3   | 0.0011   |\n",
      "| mse       | 0.0154   |\n",
      "| mse_q0    | 0.036    |\n",
      "| mse_q1    | 0.0097   |\n",
      "| mse_q2    | 0.0023   |\n",
      "| mse_q3    | 0.0011   |\n",
      "| samples   | 6.32e+03 |\n",
      "| step      | 1.58e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.351    |\n",
      "| loss      | 0.0137   |\n",
      "| loss_q0   | 0.0414   |\n",
      "| loss_q1   | 0.0104   |\n",
      "| loss_q2   | 0.00313  |\n",
      "| loss_q3   | 0.00108  |\n",
      "| mse       | 0.0137   |\n",
      "| mse_q0    | 0.0414   |\n",
      "| mse_q1    | 0.0104   |\n",
      "| mse_q2    | 0.00313  |\n",
      "| mse_q3    | 0.00108  |\n",
      "| samples   | 6.36e+03 |\n",
      "| step      | 1.59e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.362    |\n",
      "| loss      | 0.0157   |\n",
      "| loss_q0   | 0.0373   |\n",
      "| loss_q1   | 0.00955  |\n",
      "| loss_q2   | 0.0026   |\n",
      "| loss_q3   | 0.000973 |\n",
      "| mse       | 0.0157   |\n",
      "| mse_q0    | 0.0373   |\n",
      "| mse_q1    | 0.00955  |\n",
      "| mse_q2    | 0.0026   |\n",
      "| mse_q3    | 0.000973 |\n",
      "| samples   | 6.4e+03  |\n",
      "| step      | 1.6e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.515    |\n",
      "| loss      | 0.0138   |\n",
      "| loss_q0   | 0.0418   |\n",
      "| loss_q1   | 0.00968  |\n",
      "| loss_q2   | 0.00291  |\n",
      "| loss_q3   | 0.001    |\n",
      "| mse       | 0.0138   |\n",
      "| mse_q0    | 0.0418   |\n",
      "| mse_q1    | 0.00968  |\n",
      "| mse_q2    | 0.00291  |\n",
      "| mse_q3    | 0.001    |\n",
      "| samples   | 6.44e+03 |\n",
      "| step      | 1.61e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.407    |\n",
      "| loss      | 0.0124   |\n",
      "| loss_q0   | 0.0346   |\n",
      "| loss_q1   | 0.00977  |\n",
      "| loss_q2   | 0.00282  |\n",
      "| loss_q3   | 0.00105  |\n",
      "| mse       | 0.0124   |\n",
      "| mse_q0    | 0.0346   |\n",
      "| mse_q1    | 0.00977  |\n",
      "| mse_q2    | 0.00282  |\n",
      "| mse_q3    | 0.00105  |\n",
      "| samples   | 6.48e+03 |\n",
      "| step      | 1.62e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.431    |\n",
      "| loss      | 0.0129   |\n",
      "| loss_q0   | 0.0494   |\n",
      "| loss_q1   | 0.00962  |\n",
      "| loss_q2   | 0.00297  |\n",
      "| loss_q3   | 0.00103  |\n",
      "| mse       | 0.0129   |\n",
      "| mse_q0    | 0.0494   |\n",
      "| mse_q1    | 0.00962  |\n",
      "| mse_q2    | 0.00297  |\n",
      "| mse_q3    | 0.00103  |\n",
      "| samples   | 6.52e+03 |\n",
      "| step      | 1.63e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.455    |\n",
      "| loss      | 0.0132   |\n",
      "| loss_q0   | 0.0394   |\n",
      "| loss_q1   | 0.0088   |\n",
      "| loss_q2   | 0.0027   |\n",
      "| loss_q3   | 0.00118  |\n",
      "| mse       | 0.0132   |\n",
      "| mse_q0    | 0.0394   |\n",
      "| mse_q1    | 0.0088   |\n",
      "| mse_q2    | 0.0027   |\n",
      "| mse_q3    | 0.00118  |\n",
      "| samples   | 6.56e+03 |\n",
      "| step      | 1.64e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.451    |\n",
      "| loss      | 0.0106   |\n",
      "| loss_q0   | 0.0422   |\n",
      "| loss_q1   | 0.00981  |\n",
      "| loss_q2   | 0.00303  |\n",
      "| loss_q3   | 0.00103  |\n",
      "| mse       | 0.0106   |\n",
      "| mse_q0    | 0.0422   |\n",
      "| mse_q1    | 0.00981  |\n",
      "| mse_q2    | 0.00303  |\n",
      "| mse_q3    | 0.00103  |\n",
      "| samples   | 6.6e+03  |\n",
      "| step      | 1.65e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.556    |\n",
      "| loss      | 0.0177   |\n",
      "| loss_q0   | 0.0518   |\n",
      "| loss_q1   | 0.0104   |\n",
      "| loss_q2   | 0.00255  |\n",
      "| loss_q3   | 0.000995 |\n",
      "| mse       | 0.0177   |\n",
      "| mse_q0    | 0.0518   |\n",
      "| mse_q1    | 0.0104   |\n",
      "| mse_q2    | 0.00255  |\n",
      "| mse_q3    | 0.000995 |\n",
      "| samples   | 6.64e+03 |\n",
      "| step      | 1.66e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.364    |\n",
      "| loss      | 0.0132   |\n",
      "| loss_q0   | 0.045    |\n",
      "| loss_q1   | 0.00944  |\n",
      "| loss_q2   | 0.00227  |\n",
      "| loss_q3   | 0.00105  |\n",
      "| mse       | 0.0132   |\n",
      "| mse_q0    | 0.045    |\n",
      "| mse_q1    | 0.00944  |\n",
      "| mse_q2    | 0.00227  |\n",
      "| mse_q3    | 0.00105  |\n",
      "| samples   | 6.68e+03 |\n",
      "| step      | 1.67e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.406    |\n",
      "| loss      | 0.0109   |\n",
      "| loss_q0   | 0.0402   |\n",
      "| loss_q1   | 0.00843  |\n",
      "| loss_q2   | 0.00276  |\n",
      "| loss_q3   | 0.00103  |\n",
      "| mse       | 0.0109   |\n",
      "| mse_q0    | 0.0402   |\n",
      "| mse_q1    | 0.00843  |\n",
      "| mse_q2    | 0.00276  |\n",
      "| mse_q3    | 0.00103  |\n",
      "| samples   | 6.72e+03 |\n",
      "| step      | 1.68e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.452    |\n",
      "| loss      | 0.0161   |\n",
      "| loss_q0   | 0.0471   |\n",
      "| loss_q1   | 0.00927  |\n",
      "| loss_q2   | 0.00301  |\n",
      "| loss_q3   | 0.000971 |\n",
      "| mse       | 0.0161   |\n",
      "| mse_q0    | 0.0471   |\n",
      "| mse_q1    | 0.00927  |\n",
      "| mse_q2    | 0.00301  |\n",
      "| mse_q3    | 0.000971 |\n",
      "| samples   | 6.76e+03 |\n",
      "| step      | 1.69e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.373    |\n",
      "| loss      | 0.0115   |\n",
      "| loss_q0   | 0.0329   |\n",
      "| loss_q1   | 0.01     |\n",
      "| loss_q2   | 0.00244  |\n",
      "| loss_q3   | 0.000882 |\n",
      "| mse       | 0.0115   |\n",
      "| mse_q0    | 0.0329   |\n",
      "| mse_q1    | 0.01     |\n",
      "| mse_q2    | 0.00244  |\n",
      "| mse_q3    | 0.000882 |\n",
      "| samples   | 6.8e+03  |\n",
      "| step      | 1.7e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.425    |\n",
      "| loss      | 0.0152   |\n",
      "| loss_q0   | 0.0432   |\n",
      "| loss_q1   | 0.00967  |\n",
      "| loss_q2   | 0.00272  |\n",
      "| loss_q3   | 0.000954 |\n",
      "| mse       | 0.0152   |\n",
      "| mse_q0    | 0.0432   |\n",
      "| mse_q1    | 0.00967  |\n",
      "| mse_q2    | 0.00272  |\n",
      "| mse_q3    | 0.000954 |\n",
      "| samples   | 6.84e+03 |\n",
      "| step      | 1.71e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.544    |\n",
      "| loss      | 0.0135   |\n",
      "| loss_q0   | 0.0406   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.0025   |\n",
      "| loss_q3   | 0.0011   |\n",
      "| mse       | 0.0135   |\n",
      "| mse_q0    | 0.0406   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.0025   |\n",
      "| mse_q3    | 0.0011   |\n",
      "| samples   | 6.88e+03 |\n",
      "| step      | 1.72e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.39     |\n",
      "| loss      | 0.0136   |\n",
      "| loss_q0   | 0.0358   |\n",
      "| loss_q1   | 0.00895  |\n",
      "| loss_q2   | 0.00243  |\n",
      "| loss_q3   | 0.000996 |\n",
      "| mse       | 0.0136   |\n",
      "| mse_q0    | 0.0358   |\n",
      "| mse_q1    | 0.00895  |\n",
      "| mse_q2    | 0.00243  |\n",
      "| mse_q3    | 0.000996 |\n",
      "| samples   | 6.92e+03 |\n",
      "| step      | 1.73e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.486    |\n",
      "| loss      | 0.0123   |\n",
      "| loss_q0   | 0.0329   |\n",
      "| loss_q1   | 0.00989  |\n",
      "| loss_q2   | 0.00262  |\n",
      "| loss_q3   | 0.00103  |\n",
      "| mse       | 0.0123   |\n",
      "| mse_q0    | 0.0329   |\n",
      "| mse_q1    | 0.00989  |\n",
      "| mse_q2    | 0.00262  |\n",
      "| mse_q3    | 0.00103  |\n",
      "| samples   | 6.96e+03 |\n",
      "| step      | 1.74e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.408    |\n",
      "| loss      | 0.012    |\n",
      "| loss_q0   | 0.0344   |\n",
      "| loss_q1   | 0.0089   |\n",
      "| loss_q2   | 0.00279  |\n",
      "| loss_q3   | 0.000997 |\n",
      "| mse       | 0.012    |\n",
      "| mse_q0    | 0.0344   |\n",
      "| mse_q1    | 0.0089   |\n",
      "| mse_q2    | 0.00279  |\n",
      "| mse_q3    | 0.000997 |\n",
      "| samples   | 7e+03    |\n",
      "| step      | 1.75e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.442    |\n",
      "| loss      | 0.0129   |\n",
      "| loss_q0   | 0.0355   |\n",
      "| loss_q1   | 0.00865  |\n",
      "| loss_q2   | 0.00277  |\n",
      "| loss_q3   | 0.00091  |\n",
      "| mse       | 0.0129   |\n",
      "| mse_q0    | 0.0355   |\n",
      "| mse_q1    | 0.00865  |\n",
      "| mse_q2    | 0.00277  |\n",
      "| mse_q3    | 0.00091  |\n",
      "| samples   | 7.04e+03 |\n",
      "| step      | 1.76e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.456    |\n",
      "| loss      | 0.015    |\n",
      "| loss_q0   | 0.0488   |\n",
      "| loss_q1   | 0.00928  |\n",
      "| loss_q2   | 0.00278  |\n",
      "| loss_q3   | 0.00106  |\n",
      "| mse       | 0.015    |\n",
      "| mse_q0    | 0.0488   |\n",
      "| mse_q1    | 0.00928  |\n",
      "| mse_q2    | 0.00278  |\n",
      "| mse_q3    | 0.00106  |\n",
      "| samples   | 7.08e+03 |\n",
      "| step      | 1.77e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.388    |\n",
      "| loss      | 0.0134   |\n",
      "| loss_q0   | 0.0384   |\n",
      "| loss_q1   | 0.00979  |\n",
      "| loss_q2   | 0.00263  |\n",
      "| loss_q3   | 0.000953 |\n",
      "| mse       | 0.0134   |\n",
      "| mse_q0    | 0.0384   |\n",
      "| mse_q1    | 0.00979  |\n",
      "| mse_q2    | 0.00263  |\n",
      "| mse_q3    | 0.000953 |\n",
      "| samples   | 7.12e+03 |\n",
      "| step      | 1.78e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.481    |\n",
      "| loss      | 0.0143   |\n",
      "| loss_q0   | 0.04     |\n",
      "| loss_q1   | 0.0095   |\n",
      "| loss_q2   | 0.00311  |\n",
      "| loss_q3   | 0.000994 |\n",
      "| mse       | 0.0143   |\n",
      "| mse_q0    | 0.04     |\n",
      "| mse_q1    | 0.0095   |\n",
      "| mse_q2    | 0.00311  |\n",
      "| mse_q3    | 0.000994 |\n",
      "| samples   | 7.16e+03 |\n",
      "| step      | 1.79e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.388    |\n",
      "| loss      | 0.0115   |\n",
      "| loss_q0   | 0.036    |\n",
      "| loss_q1   | 0.00952  |\n",
      "| loss_q2   | 0.00269  |\n",
      "| loss_q3   | 0.00104  |\n",
      "| mse       | 0.0115   |\n",
      "| mse_q0    | 0.036    |\n",
      "| mse_q1    | 0.00952  |\n",
      "| mse_q2    | 0.00269  |\n",
      "| mse_q3    | 0.00104  |\n",
      "| samples   | 7.2e+03  |\n",
      "| step      | 1.8e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.322    |\n",
      "| loss      | 0.0123   |\n",
      "| loss_q0   | 0.0361   |\n",
      "| loss_q1   | 0.0091   |\n",
      "| loss_q2   | 0.00245  |\n",
      "| loss_q3   | 0.000892 |\n",
      "| mse       | 0.0123   |\n",
      "| mse_q0    | 0.0361   |\n",
      "| mse_q1    | 0.0091   |\n",
      "| mse_q2    | 0.00245  |\n",
      "| mse_q3    | 0.000892 |\n",
      "| samples   | 7.24e+03 |\n",
      "| step      | 1.81e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.408    |\n",
      "| loss      | 0.0142   |\n",
      "| loss_q0   | 0.0428   |\n",
      "| loss_q1   | 0.01     |\n",
      "| loss_q2   | 0.00294  |\n",
      "| loss_q3   | 0.000915 |\n",
      "| mse       | 0.0142   |\n",
      "| mse_q0    | 0.0428   |\n",
      "| mse_q1    | 0.01     |\n",
      "| mse_q2    | 0.00294  |\n",
      "| mse_q3    | 0.000915 |\n",
      "| samples   | 7.28e+03 |\n",
      "| step      | 1.82e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.351    |\n",
      "| loss      | 0.0122   |\n",
      "| loss_q0   | 0.0378   |\n",
      "| loss_q1   | 0.00964  |\n",
      "| loss_q2   | 0.00285  |\n",
      "| loss_q3   | 0.000981 |\n",
      "| mse       | 0.0122   |\n",
      "| mse_q0    | 0.0378   |\n",
      "| mse_q1    | 0.00964  |\n",
      "| mse_q2    | 0.00285  |\n",
      "| mse_q3    | 0.000981 |\n",
      "| samples   | 7.32e+03 |\n",
      "| step      | 1.83e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.378    |\n",
      "| loss      | 0.0145   |\n",
      "| loss_q0   | 0.0411   |\n",
      "| loss_q1   | 0.00932  |\n",
      "| loss_q2   | 0.00287  |\n",
      "| loss_q3   | 0.000895 |\n",
      "| mse       | 0.0145   |\n",
      "| mse_q0    | 0.0411   |\n",
      "| mse_q1    | 0.00932  |\n",
      "| mse_q2    | 0.00287  |\n",
      "| mse_q3    | 0.000895 |\n",
      "| samples   | 7.36e+03 |\n",
      "| step      | 1.84e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.439    |\n",
      "| loss      | 0.0149   |\n",
      "| loss_q0   | 0.0442   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00281  |\n",
      "| loss_q3   | 0.000898 |\n",
      "| mse       | 0.0149   |\n",
      "| mse_q0    | 0.0442   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00281  |\n",
      "| mse_q3    | 0.000898 |\n",
      "| samples   | 7.4e+03  |\n",
      "| step      | 1.85e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.473    |\n",
      "| loss      | 0.0146   |\n",
      "| loss_q0   | 0.0407   |\n",
      "| loss_q1   | 0.00977  |\n",
      "| loss_q2   | 0.00264  |\n",
      "| loss_q3   | 0.00104  |\n",
      "| mse       | 0.0146   |\n",
      "| mse_q0    | 0.0407   |\n",
      "| mse_q1    | 0.00977  |\n",
      "| mse_q2    | 0.00264  |\n",
      "| mse_q3    | 0.00104  |\n",
      "| samples   | 7.44e+03 |\n",
      "| step      | 1.86e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.354    |\n",
      "| loss      | 0.0128   |\n",
      "| loss_q0   | 0.0401   |\n",
      "| loss_q1   | 0.00884  |\n",
      "| loss_q2   | 0.00259  |\n",
      "| loss_q3   | 0.00104  |\n",
      "| mse       | 0.0128   |\n",
      "| mse_q0    | 0.0401   |\n",
      "| mse_q1    | 0.00884  |\n",
      "| mse_q2    | 0.00259  |\n",
      "| mse_q3    | 0.00104  |\n",
      "| samples   | 7.48e+03 |\n",
      "| step      | 1.87e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.469    |\n",
      "| loss      | 0.0174   |\n",
      "| loss_q0   | 0.045    |\n",
      "| loss_q1   | 0.0091   |\n",
      "| loss_q2   | 0.00282  |\n",
      "| loss_q3   | 0.000995 |\n",
      "| mse       | 0.0174   |\n",
      "| mse_q0    | 0.045    |\n",
      "| mse_q1    | 0.0091   |\n",
      "| mse_q2    | 0.00282  |\n",
      "| mse_q3    | 0.000995 |\n",
      "| samples   | 7.52e+03 |\n",
      "| step      | 1.88e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.431    |\n",
      "| loss      | 0.015    |\n",
      "| loss_q0   | 0.0513   |\n",
      "| loss_q1   | 0.00828  |\n",
      "| loss_q2   | 0.00316  |\n",
      "| loss_q3   | 0.00101  |\n",
      "| mse       | 0.015    |\n",
      "| mse_q0    | 0.0513   |\n",
      "| mse_q1    | 0.00828  |\n",
      "| mse_q2    | 0.00316  |\n",
      "| mse_q3    | 0.00101  |\n",
      "| samples   | 7.56e+03 |\n",
      "| step      | 1.89e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.506    |\n",
      "| loss      | 0.0108   |\n",
      "| loss_q0   | 0.0386   |\n",
      "| loss_q1   | 0.00925  |\n",
      "| loss_q2   | 0.00258  |\n",
      "| loss_q3   | 0.00109  |\n",
      "| mse       | 0.0108   |\n",
      "| mse_q0    | 0.0386   |\n",
      "| mse_q1    | 0.00925  |\n",
      "| mse_q2    | 0.00258  |\n",
      "| mse_q3    | 0.00109  |\n",
      "| samples   | 7.6e+03  |\n",
      "| step      | 1.9e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.472    |\n",
      "| loss      | 0.0123   |\n",
      "| loss_q0   | 0.0395   |\n",
      "| loss_q1   | 0.00894  |\n",
      "| loss_q2   | 0.00288  |\n",
      "| loss_q3   | 0.00102  |\n",
      "| mse       | 0.0123   |\n",
      "| mse_q0    | 0.0395   |\n",
      "| mse_q1    | 0.00894  |\n",
      "| mse_q2    | 0.00288  |\n",
      "| mse_q3    | 0.00102  |\n",
      "| samples   | 7.64e+03 |\n",
      "| step      | 1.91e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.463    |\n",
      "| loss      | 0.0109   |\n",
      "| loss_q0   | 0.0408   |\n",
      "| loss_q1   | 0.00814  |\n",
      "| loss_q2   | 0.00267  |\n",
      "| loss_q3   | 0.00104  |\n",
      "| mse       | 0.0109   |\n",
      "| mse_q0    | 0.0408   |\n",
      "| mse_q1    | 0.00814  |\n",
      "| mse_q2    | 0.00267  |\n",
      "| mse_q3    | 0.00104  |\n",
      "| samples   | 7.68e+03 |\n",
      "| step      | 1.92e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.335    |\n",
      "| loss      | 0.0126   |\n",
      "| loss_q0   | 0.0348   |\n",
      "| loss_q1   | 0.00935  |\n",
      "| loss_q2   | 0.00254  |\n",
      "| loss_q3   | 0.000958 |\n",
      "| mse       | 0.0126   |\n",
      "| mse_q0    | 0.0348   |\n",
      "| mse_q1    | 0.00935  |\n",
      "| mse_q2    | 0.00254  |\n",
      "| mse_q3    | 0.000958 |\n",
      "| samples   | 7.72e+03 |\n",
      "| step      | 1.93e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.311    |\n",
      "| loss      | 0.0106   |\n",
      "| loss_q0   | 0.0289   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.0028   |\n",
      "| loss_q3   | 0.000911 |\n",
      "| mse       | 0.0106   |\n",
      "| mse_q0    | 0.0289   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.0028   |\n",
      "| mse_q3    | 0.000911 |\n",
      "| samples   | 7.76e+03 |\n",
      "| step      | 1.94e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.418    |\n",
      "| loss      | 0.0133   |\n",
      "| loss_q0   | 0.032    |\n",
      "| loss_q1   | 0.00863  |\n",
      "| loss_q2   | 0.00305  |\n",
      "| loss_q3   | 0.000884 |\n",
      "| mse       | 0.0133   |\n",
      "| mse_q0    | 0.032    |\n",
      "| mse_q1    | 0.00863  |\n",
      "| mse_q2    | 0.00305  |\n",
      "| mse_q3    | 0.000884 |\n",
      "| samples   | 7.8e+03  |\n",
      "| step      | 1.95e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.37     |\n",
      "| loss      | 0.0119   |\n",
      "| loss_q0   | 0.035    |\n",
      "| loss_q1   | 0.0081   |\n",
      "| loss_q2   | 0.00253  |\n",
      "| loss_q3   | 0.000917 |\n",
      "| mse       | 0.0119   |\n",
      "| mse_q0    | 0.035    |\n",
      "| mse_q1    | 0.0081   |\n",
      "| mse_q2    | 0.00253  |\n",
      "| mse_q3    | 0.000917 |\n",
      "| samples   | 7.84e+03 |\n",
      "| step      | 1.96e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.371    |\n",
      "| loss      | 0.0132   |\n",
      "| loss_q0   | 0.0371   |\n",
      "| loss_q1   | 0.00839  |\n",
      "| loss_q2   | 0.00282  |\n",
      "| loss_q3   | 0.000895 |\n",
      "| mse       | 0.0132   |\n",
      "| mse_q0    | 0.0371   |\n",
      "| mse_q1    | 0.00839  |\n",
      "| mse_q2    | 0.00282  |\n",
      "| mse_q3    | 0.000895 |\n",
      "| samples   | 7.88e+03 |\n",
      "| step      | 1.97e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.451    |\n",
      "| loss      | 0.0116   |\n",
      "| loss_q0   | 0.0292   |\n",
      "| loss_q1   | 0.00916  |\n",
      "| loss_q2   | 0.0025   |\n",
      "| loss_q3   | 0.000998 |\n",
      "| mse       | 0.0116   |\n",
      "| mse_q0    | 0.0292   |\n",
      "| mse_q1    | 0.00916  |\n",
      "| mse_q2    | 0.0025   |\n",
      "| mse_q3    | 0.000998 |\n",
      "| samples   | 7.92e+03 |\n",
      "| step      | 1.98e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.331    |\n",
      "| loss      | 0.0103   |\n",
      "| loss_q0   | 0.033    |\n",
      "| loss_q1   | 0.00891  |\n",
      "| loss_q2   | 0.00231  |\n",
      "| loss_q3   | 0.000823 |\n",
      "| mse       | 0.0103   |\n",
      "| mse_q0    | 0.033    |\n",
      "| mse_q1    | 0.00891  |\n",
      "| mse_q2    | 0.00231  |\n",
      "| mse_q3    | 0.000823 |\n",
      "| samples   | 7.96e+03 |\n",
      "| step      | 1.99e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.393    |\n",
      "| loss      | 0.0108   |\n",
      "| loss_q0   | 0.0308   |\n",
      "| loss_q1   | 0.0106   |\n",
      "| loss_q2   | 0.00236  |\n",
      "| loss_q3   | 0.000867 |\n",
      "| mse       | 0.0108   |\n",
      "| mse_q0    | 0.0308   |\n",
      "| mse_q1    | 0.0106   |\n",
      "| mse_q2    | 0.00236  |\n",
      "| mse_q3    | 0.000867 |\n",
      "| samples   | 8e+03    |\n",
      "| step      | 2e+03    |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.395    |\n",
      "| loss      | 0.0125   |\n",
      "| loss_q0   | 0.0363   |\n",
      "| loss_q1   | 0.00991  |\n",
      "| loss_q2   | 0.00294  |\n",
      "| loss_q3   | 0.000869 |\n",
      "| mse       | 0.0125   |\n",
      "| mse_q0    | 0.0363   |\n",
      "| mse_q1    | 0.00991  |\n",
      "| mse_q2    | 0.00294  |\n",
      "| mse_q3    | 0.000869 |\n",
      "| samples   | 8.04e+03 |\n",
      "| step      | 2.01e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.418    |\n",
      "| loss      | 0.0133   |\n",
      "| loss_q0   | 0.0384   |\n",
      "| loss_q1   | 0.00972  |\n",
      "| loss_q2   | 0.00266  |\n",
      "| loss_q3   | 0.000971 |\n",
      "| mse       | 0.0133   |\n",
      "| mse_q0    | 0.0384   |\n",
      "| mse_q1    | 0.00972  |\n",
      "| mse_q2    | 0.00266  |\n",
      "| mse_q3    | 0.000971 |\n",
      "| samples   | 8.08e+03 |\n",
      "| step      | 2.02e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.348    |\n",
      "| loss      | 0.014    |\n",
      "| loss_q0   | 0.0411   |\n",
      "| loss_q1   | 0.00963  |\n",
      "| loss_q2   | 0.00255  |\n",
      "| loss_q3   | 0.000953 |\n",
      "| mse       | 0.014    |\n",
      "| mse_q0    | 0.0411   |\n",
      "| mse_q1    | 0.00963  |\n",
      "| mse_q2    | 0.00255  |\n",
      "| mse_q3    | 0.000953 |\n",
      "| samples   | 8.12e+03 |\n",
      "| step      | 2.03e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.315    |\n",
      "| loss      | 0.0129   |\n",
      "| loss_q0   | 0.0358   |\n",
      "| loss_q1   | 0.00958  |\n",
      "| loss_q2   | 0.00266  |\n",
      "| loss_q3   | 0.000851 |\n",
      "| mse       | 0.0129   |\n",
      "| mse_q0    | 0.0358   |\n",
      "| mse_q1    | 0.00958  |\n",
      "| mse_q2    | 0.00266  |\n",
      "| mse_q3    | 0.000851 |\n",
      "| samples   | 8.16e+03 |\n",
      "| step      | 2.04e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.46     |\n",
      "| loss      | 0.0161   |\n",
      "| loss_q0   | 0.0419   |\n",
      "| loss_q1   | 0.00892  |\n",
      "| loss_q2   | 0.00273  |\n",
      "| loss_q3   | 0.00106  |\n",
      "| mse       | 0.0161   |\n",
      "| mse_q0    | 0.0419   |\n",
      "| mse_q1    | 0.00892  |\n",
      "| mse_q2    | 0.00273  |\n",
      "| mse_q3    | 0.00106  |\n",
      "| samples   | 8.2e+03  |\n",
      "| step      | 2.05e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.348    |\n",
      "| loss      | 0.0159   |\n",
      "| loss_q0   | 0.05     |\n",
      "| loss_q1   | 0.00853  |\n",
      "| loss_q2   | 0.00255  |\n",
      "| loss_q3   | 0.000863 |\n",
      "| mse       | 0.0159   |\n",
      "| mse_q0    | 0.05     |\n",
      "| mse_q1    | 0.00853  |\n",
      "| mse_q2    | 0.00255  |\n",
      "| mse_q3    | 0.000863 |\n",
      "| samples   | 8.24e+03 |\n",
      "| step      | 2.06e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.351    |\n",
      "| loss      | 0.0136   |\n",
      "| loss_q0   | 0.04     |\n",
      "| loss_q1   | 0.0092   |\n",
      "| loss_q2   | 0.00264  |\n",
      "| loss_q3   | 0.000965 |\n",
      "| mse       | 0.0136   |\n",
      "| mse_q0    | 0.04     |\n",
      "| mse_q1    | 0.0092   |\n",
      "| mse_q2    | 0.00264  |\n",
      "| mse_q3    | 0.000965 |\n",
      "| samples   | 8.28e+03 |\n",
      "| step      | 2.07e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.339    |\n",
      "| loss      | 0.00971  |\n",
      "| loss_q0   | 0.0328   |\n",
      "| loss_q1   | 0.00849  |\n",
      "| loss_q2   | 0.0023   |\n",
      "| loss_q3   | 0.000851 |\n",
      "| mse       | 0.00971  |\n",
      "| mse_q0    | 0.0328   |\n",
      "| mse_q1    | 0.00849  |\n",
      "| mse_q2    | 0.0023   |\n",
      "| mse_q3    | 0.000851 |\n",
      "| samples   | 8.32e+03 |\n",
      "| step      | 2.08e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.363    |\n",
      "| loss      | 0.0129   |\n",
      "| loss_q0   | 0.0441   |\n",
      "| loss_q1   | 0.00987  |\n",
      "| loss_q2   | 0.00252  |\n",
      "| loss_q3   | 0.000828 |\n",
      "| mse       | 0.0129   |\n",
      "| mse_q0    | 0.0441   |\n",
      "| mse_q1    | 0.00987  |\n",
      "| mse_q2    | 0.00252  |\n",
      "| mse_q3    | 0.000828 |\n",
      "| samples   | 8.36e+03 |\n",
      "| step      | 2.09e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.373    |\n",
      "| loss      | 0.0135   |\n",
      "| loss_q0   | 0.0428   |\n",
      "| loss_q1   | 0.00957  |\n",
      "| loss_q2   | 0.00251  |\n",
      "| loss_q3   | 0.000856 |\n",
      "| mse       | 0.0135   |\n",
      "| mse_q0    | 0.0428   |\n",
      "| mse_q1    | 0.00957  |\n",
      "| mse_q2    | 0.00251  |\n",
      "| mse_q3    | 0.000856 |\n",
      "| samples   | 8.4e+03  |\n",
      "| step      | 2.1e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.384    |\n",
      "| loss      | 0.0104   |\n",
      "| loss_q0   | 0.0322   |\n",
      "| loss_q1   | 0.00862  |\n",
      "| loss_q2   | 0.00231  |\n",
      "| loss_q3   | 0.000887 |\n",
      "| mse       | 0.0104   |\n",
      "| mse_q0    | 0.0322   |\n",
      "| mse_q1    | 0.00862  |\n",
      "| mse_q2    | 0.00231  |\n",
      "| mse_q3    | 0.000887 |\n",
      "| samples   | 8.44e+03 |\n",
      "| step      | 2.11e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.356    |\n",
      "| loss      | 0.0123   |\n",
      "| loss_q0   | 0.037    |\n",
      "| loss_q1   | 0.00777  |\n",
      "| loss_q2   | 0.00257  |\n",
      "| loss_q3   | 0.000893 |\n",
      "| mse       | 0.0123   |\n",
      "| mse_q0    | 0.037    |\n",
      "| mse_q1    | 0.00777  |\n",
      "| mse_q2    | 0.00257  |\n",
      "| mse_q3    | 0.000893 |\n",
      "| samples   | 8.48e+03 |\n",
      "| step      | 2.12e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.404    |\n",
      "| loss      | 0.0147   |\n",
      "| loss_q0   | 0.0398   |\n",
      "| loss_q1   | 0.00889  |\n",
      "| loss_q2   | 0.00264  |\n",
      "| loss_q3   | 0.000906 |\n",
      "| mse       | 0.0147   |\n",
      "| mse_q0    | 0.0398   |\n",
      "| mse_q1    | 0.00889  |\n",
      "| mse_q2    | 0.00264  |\n",
      "| mse_q3    | 0.000906 |\n",
      "| samples   | 8.52e+03 |\n",
      "| step      | 2.13e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.469    |\n",
      "| loss      | 0.0165   |\n",
      "| loss_q0   | 0.0513   |\n",
      "| loss_q1   | 0.00816  |\n",
      "| loss_q2   | 0.00267  |\n",
      "| loss_q3   | 0.00084  |\n",
      "| mse       | 0.0165   |\n",
      "| mse_q0    | 0.0513   |\n",
      "| mse_q1    | 0.00816  |\n",
      "| mse_q2    | 0.00267  |\n",
      "| mse_q3    | 0.00084  |\n",
      "| samples   | 8.56e+03 |\n",
      "| step      | 2.14e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.495    |\n",
      "| loss      | 0.015    |\n",
      "| loss_q0   | 0.042    |\n",
      "| loss_q1   | 0.00946  |\n",
      "| loss_q2   | 0.00242  |\n",
      "| loss_q3   | 0.00105  |\n",
      "| mse       | 0.015    |\n",
      "| mse_q0    | 0.042    |\n",
      "| mse_q1    | 0.00946  |\n",
      "| mse_q2    | 0.00242  |\n",
      "| mse_q3    | 0.00105  |\n",
      "| samples   | 8.6e+03  |\n",
      "| step      | 2.15e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.47     |\n",
      "| loss      | 0.0128   |\n",
      "| loss_q0   | 0.0381   |\n",
      "| loss_q1   | 0.00953  |\n",
      "| loss_q2   | 0.00269  |\n",
      "| loss_q3   | 0.00111  |\n",
      "| mse       | 0.0128   |\n",
      "| mse_q0    | 0.0381   |\n",
      "| mse_q1    | 0.00953  |\n",
      "| mse_q2    | 0.00269  |\n",
      "| mse_q3    | 0.00111  |\n",
      "| samples   | 8.64e+03 |\n",
      "| step      | 2.16e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.521    |\n",
      "| loss      | 0.0134   |\n",
      "| loss_q0   | 0.0389   |\n",
      "| loss_q1   | 0.00967  |\n",
      "| loss_q2   | 0.0025   |\n",
      "| loss_q3   | 0.000946 |\n",
      "| mse       | 0.0134   |\n",
      "| mse_q0    | 0.0389   |\n",
      "| mse_q1    | 0.00967  |\n",
      "| mse_q2    | 0.0025   |\n",
      "| mse_q3    | 0.000946 |\n",
      "| samples   | 8.68e+03 |\n",
      "| step      | 2.17e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.456    |\n",
      "| loss      | 0.0133   |\n",
      "| loss_q0   | 0.0371   |\n",
      "| loss_q1   | 0.00954  |\n",
      "| loss_q2   | 0.0027   |\n",
      "| loss_q3   | 0.000957 |\n",
      "| mse       | 0.0133   |\n",
      "| mse_q0    | 0.0371   |\n",
      "| mse_q1    | 0.00954  |\n",
      "| mse_q2    | 0.0027   |\n",
      "| mse_q3    | 0.000957 |\n",
      "| samples   | 8.72e+03 |\n",
      "| step      | 2.18e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.322    |\n",
      "| loss      | 0.0143   |\n",
      "| loss_q0   | 0.0404   |\n",
      "| loss_q1   | 0.0095   |\n",
      "| loss_q2   | 0.00237  |\n",
      "| loss_q3   | 0.000937 |\n",
      "| mse       | 0.0143   |\n",
      "| mse_q0    | 0.0404   |\n",
      "| mse_q1    | 0.0095   |\n",
      "| mse_q2    | 0.00237  |\n",
      "| mse_q3    | 0.000937 |\n",
      "| samples   | 8.76e+03 |\n",
      "| step      | 2.19e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.318    |\n",
      "| loss      | 0.0127   |\n",
      "| loss_q0   | 0.0462   |\n",
      "| loss_q1   | 0.00937  |\n",
      "| loss_q2   | 0.00247  |\n",
      "| loss_q3   | 0.000862 |\n",
      "| mse       | 0.0127   |\n",
      "| mse_q0    | 0.0462   |\n",
      "| mse_q1    | 0.00937  |\n",
      "| mse_q2    | 0.00247  |\n",
      "| mse_q3    | 0.000862 |\n",
      "| samples   | 8.8e+03  |\n",
      "| step      | 2.2e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.261    |\n",
      "| loss      | 0.0137   |\n",
      "| loss_q0   | 0.0375   |\n",
      "| loss_q1   | 0.00922  |\n",
      "| loss_q2   | 0.00232  |\n",
      "| loss_q3   | 0.000796 |\n",
      "| mse       | 0.0137   |\n",
      "| mse_q0    | 0.0375   |\n",
      "| mse_q1    | 0.00922  |\n",
      "| mse_q2    | 0.00232  |\n",
      "| mse_q3    | 0.000796 |\n",
      "| samples   | 8.84e+03 |\n",
      "| step      | 2.21e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.359    |\n",
      "| loss      | 0.0117   |\n",
      "| loss_q0   | 0.0385   |\n",
      "| loss_q1   | 0.00783  |\n",
      "| loss_q2   | 0.00273  |\n",
      "| loss_q3   | 0.000848 |\n",
      "| mse       | 0.0117   |\n",
      "| mse_q0    | 0.0385   |\n",
      "| mse_q1    | 0.00783  |\n",
      "| mse_q2    | 0.00273  |\n",
      "| mse_q3    | 0.000848 |\n",
      "| samples   | 8.88e+03 |\n",
      "| step      | 2.22e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.371    |\n",
      "| loss      | 0.0129   |\n",
      "| loss_q0   | 0.0414   |\n",
      "| loss_q1   | 0.0101   |\n",
      "| loss_q2   | 0.00299  |\n",
      "| loss_q3   | 0.000813 |\n",
      "| mse       | 0.0129   |\n",
      "| mse_q0    | 0.0414   |\n",
      "| mse_q1    | 0.0101   |\n",
      "| mse_q2    | 0.00299  |\n",
      "| mse_q3    | 0.000813 |\n",
      "| samples   | 8.92e+03 |\n",
      "| step      | 2.23e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.359    |\n",
      "| loss      | 0.0108   |\n",
      "| loss_q0   | 0.0307   |\n",
      "| loss_q1   | 0.0098   |\n",
      "| loss_q2   | 0.00268  |\n",
      "| loss_q3   | 0.000878 |\n",
      "| mse       | 0.0108   |\n",
      "| mse_q0    | 0.0307   |\n",
      "| mse_q1    | 0.0098   |\n",
      "| mse_q2    | 0.00268  |\n",
      "| mse_q3    | 0.000878 |\n",
      "| samples   | 8.96e+03 |\n",
      "| step      | 2.24e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.333    |\n",
      "| loss      | 0.0126   |\n",
      "| loss_q0   | 0.0405   |\n",
      "| loss_q1   | 0.00899  |\n",
      "| loss_q2   | 0.0022   |\n",
      "| loss_q3   | 0.000866 |\n",
      "| mse       | 0.0126   |\n",
      "| mse_q0    | 0.0405   |\n",
      "| mse_q1    | 0.00899  |\n",
      "| mse_q2    | 0.0022   |\n",
      "| mse_q3    | 0.000866 |\n",
      "| samples   | 9e+03    |\n",
      "| step      | 2.25e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.407    |\n",
      "| loss      | 0.0155   |\n",
      "| loss_q0   | 0.0468   |\n",
      "| loss_q1   | 0.0102   |\n",
      "| loss_q2   | 0.00327  |\n",
      "| loss_q3   | 0.000885 |\n",
      "| mse       | 0.0155   |\n",
      "| mse_q0    | 0.0468   |\n",
      "| mse_q1    | 0.0102   |\n",
      "| mse_q2    | 0.00327  |\n",
      "| mse_q3    | 0.000885 |\n",
      "| samples   | 9.04e+03 |\n",
      "| step      | 2.26e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.414    |\n",
      "| loss      | 0.0152   |\n",
      "| loss_q0   | 0.0439   |\n",
      "| loss_q1   | 0.00901  |\n",
      "| loss_q2   | 0.00286  |\n",
      "| loss_q3   | 0.000891 |\n",
      "| mse       | 0.0152   |\n",
      "| mse_q0    | 0.0439   |\n",
      "| mse_q1    | 0.00901  |\n",
      "| mse_q2    | 0.00286  |\n",
      "| mse_q3    | 0.000891 |\n",
      "| samples   | 9.08e+03 |\n",
      "| step      | 2.27e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.422    |\n",
      "| loss      | 0.0133   |\n",
      "| loss_q0   | 0.0437   |\n",
      "| loss_q1   | 0.00895  |\n",
      "| loss_q2   | 0.00267  |\n",
      "| loss_q3   | 0.000911 |\n",
      "| mse       | 0.0133   |\n",
      "| mse_q0    | 0.0437   |\n",
      "| mse_q1    | 0.00895  |\n",
      "| mse_q2    | 0.00267  |\n",
      "| mse_q3    | 0.000911 |\n",
      "| samples   | 9.12e+03 |\n",
      "| step      | 2.28e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.304    |\n",
      "| loss      | 0.0127   |\n",
      "| loss_q0   | 0.051    |\n",
      "| loss_q1   | 0.00823  |\n",
      "| loss_q2   | 0.00209  |\n",
      "| loss_q3   | 0.000814 |\n",
      "| mse       | 0.0127   |\n",
      "| mse_q0    | 0.051    |\n",
      "| mse_q1    | 0.00823  |\n",
      "| mse_q2    | 0.00209  |\n",
      "| mse_q3    | 0.000814 |\n",
      "| samples   | 9.16e+03 |\n",
      "| step      | 2.29e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.353    |\n",
      "| loss      | 0.0111   |\n",
      "| loss_q0   | 0.0379   |\n",
      "| loss_q1   | 0.00785  |\n",
      "| loss_q2   | 0.00258  |\n",
      "| loss_q3   | 0.000914 |\n",
      "| mse       | 0.0111   |\n",
      "| mse_q0    | 0.0379   |\n",
      "| mse_q1    | 0.00785  |\n",
      "| mse_q2    | 0.00258  |\n",
      "| mse_q3    | 0.000914 |\n",
      "| samples   | 9.2e+03  |\n",
      "| step      | 2.3e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.371    |\n",
      "| loss      | 0.0127   |\n",
      "| loss_q0   | 0.0498   |\n",
      "| loss_q1   | 0.00843  |\n",
      "| loss_q2   | 0.00249  |\n",
      "| loss_q3   | 0.000903 |\n",
      "| mse       | 0.0127   |\n",
      "| mse_q0    | 0.0498   |\n",
      "| mse_q1    | 0.00843  |\n",
      "| mse_q2    | 0.00249  |\n",
      "| mse_q3    | 0.000903 |\n",
      "| samples   | 9.24e+03 |\n",
      "| step      | 2.31e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.4      |\n",
      "| loss      | 0.015    |\n",
      "| loss_q0   | 0.043    |\n",
      "| loss_q1   | 0.00798  |\n",
      "| loss_q2   | 0.00262  |\n",
      "| loss_q3   | 0.000926 |\n",
      "| mse       | 0.015    |\n",
      "| mse_q0    | 0.043    |\n",
      "| mse_q1    | 0.00798  |\n",
      "| mse_q2    | 0.00262  |\n",
      "| mse_q3    | 0.000926 |\n",
      "| samples   | 9.28e+03 |\n",
      "| step      | 2.32e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.399    |\n",
      "| loss      | 0.0159   |\n",
      "| loss_q0   | 0.0452   |\n",
      "| loss_q1   | 0.00917  |\n",
      "| loss_q2   | 0.00259  |\n",
      "| loss_q3   | 0.000923 |\n",
      "| mse       | 0.0159   |\n",
      "| mse_q0    | 0.0452   |\n",
      "| mse_q1    | 0.00917  |\n",
      "| mse_q2    | 0.00259  |\n",
      "| mse_q3    | 0.000923 |\n",
      "| samples   | 9.32e+03 |\n",
      "| step      | 2.33e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.314    |\n",
      "| loss      | 0.0155   |\n",
      "| loss_q0   | 0.0412   |\n",
      "| loss_q1   | 0.00892  |\n",
      "| loss_q2   | 0.00248  |\n",
      "| loss_q3   | 0.000912 |\n",
      "| mse       | 0.0155   |\n",
      "| mse_q0    | 0.0412   |\n",
      "| mse_q1    | 0.00892  |\n",
      "| mse_q2    | 0.00248  |\n",
      "| mse_q3    | 0.000912 |\n",
      "| samples   | 9.36e+03 |\n",
      "| step      | 2.34e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.282    |\n",
      "| loss      | 0.0115   |\n",
      "| loss_q0   | 0.0366   |\n",
      "| loss_q1   | 0.00785  |\n",
      "| loss_q2   | 0.00235  |\n",
      "| loss_q3   | 0.000836 |\n",
      "| mse       | 0.0115   |\n",
      "| mse_q0    | 0.0366   |\n",
      "| mse_q1    | 0.00785  |\n",
      "| mse_q2    | 0.00235  |\n",
      "| mse_q3    | 0.000836 |\n",
      "| samples   | 9.4e+03  |\n",
      "| step      | 2.35e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.305    |\n",
      "| loss      | 0.0144   |\n",
      "| loss_q0   | 0.0387   |\n",
      "| loss_q1   | 0.00967  |\n",
      "| loss_q2   | 0.00244  |\n",
      "| loss_q3   | 0.000829 |\n",
      "| mse       | 0.0144   |\n",
      "| mse_q0    | 0.0387   |\n",
      "| mse_q1    | 0.00967  |\n",
      "| mse_q2    | 0.00244  |\n",
      "| mse_q3    | 0.000829 |\n",
      "| samples   | 9.44e+03 |\n",
      "| step      | 2.36e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.296    |\n",
      "| loss      | 0.013    |\n",
      "| loss_q0   | 0.0393   |\n",
      "| loss_q1   | 0.00961  |\n",
      "| loss_q2   | 0.00276  |\n",
      "| loss_q3   | 0.000801 |\n",
      "| mse       | 0.013    |\n",
      "| mse_q0    | 0.0393   |\n",
      "| mse_q1    | 0.00961  |\n",
      "| mse_q2    | 0.00276  |\n",
      "| mse_q3    | 0.000801 |\n",
      "| samples   | 9.48e+03 |\n",
      "| step      | 2.37e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.342    |\n",
      "| loss      | 0.0171   |\n",
      "| loss_q0   | 0.0576   |\n",
      "| loss_q1   | 0.00888  |\n",
      "| loss_q2   | 0.00253  |\n",
      "| loss_q3   | 0.000815 |\n",
      "| mse       | 0.0171   |\n",
      "| mse_q0    | 0.0576   |\n",
      "| mse_q1    | 0.00888  |\n",
      "| mse_q2    | 0.00253  |\n",
      "| mse_q3    | 0.000815 |\n",
      "| samples   | 9.52e+03 |\n",
      "| step      | 2.38e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.376    |\n",
      "| loss      | 0.0142   |\n",
      "| loss_q0   | 0.045    |\n",
      "| loss_q1   | 0.00833  |\n",
      "| loss_q2   | 0.00246  |\n",
      "| loss_q3   | 0.000921 |\n",
      "| mse       | 0.0142   |\n",
      "| mse_q0    | 0.045    |\n",
      "| mse_q1    | 0.00833  |\n",
      "| mse_q2    | 0.00246  |\n",
      "| mse_q3    | 0.000921 |\n",
      "| samples   | 9.56e+03 |\n",
      "| step      | 2.39e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.384    |\n",
      "| loss      | 0.0138   |\n",
      "| loss_q0   | 0.0465   |\n",
      "| loss_q1   | 0.009    |\n",
      "| loss_q2   | 0.00276  |\n",
      "| loss_q3   | 0.000859 |\n",
      "| mse       | 0.0138   |\n",
      "| mse_q0    | 0.0465   |\n",
      "| mse_q1    | 0.009    |\n",
      "| mse_q2    | 0.00276  |\n",
      "| mse_q3    | 0.000859 |\n",
      "| samples   | 9.6e+03  |\n",
      "| step      | 2.4e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.257    |\n",
      "| loss      | 0.00999  |\n",
      "| loss_q0   | 0.0384   |\n",
      "| loss_q1   | 0.00921  |\n",
      "| loss_q2   | 0.00229  |\n",
      "| loss_q3   | 0.000806 |\n",
      "| mse       | 0.00999  |\n",
      "| mse_q0    | 0.0384   |\n",
      "| mse_q1    | 0.00921  |\n",
      "| mse_q2    | 0.00229  |\n",
      "| mse_q3    | 0.000806 |\n",
      "| samples   | 9.64e+03 |\n",
      "| step      | 2.41e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.356    |\n",
      "| loss      | 0.0143   |\n",
      "| loss_q0   | 0.0425   |\n",
      "| loss_q1   | 0.00775  |\n",
      "| loss_q2   | 0.00254  |\n",
      "| loss_q3   | 0.000819 |\n",
      "| mse       | 0.0143   |\n",
      "| mse_q0    | 0.0425   |\n",
      "| mse_q1    | 0.00775  |\n",
      "| mse_q2    | 0.00254  |\n",
      "| mse_q3    | 0.000819 |\n",
      "| samples   | 9.68e+03 |\n",
      "| step      | 2.42e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.372    |\n",
      "| loss      | 0.0123   |\n",
      "| loss_q0   | 0.0297   |\n",
      "| loss_q1   | 0.00943  |\n",
      "| loss_q2   | 0.00289  |\n",
      "| loss_q3   | 0.000757 |\n",
      "| mse       | 0.0123   |\n",
      "| mse_q0    | 0.0297   |\n",
      "| mse_q1    | 0.00943  |\n",
      "| mse_q2    | 0.00289  |\n",
      "| mse_q3    | 0.000757 |\n",
      "| samples   | 9.72e+03 |\n",
      "| step      | 2.43e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.259    |\n",
      "| loss      | 0.0108   |\n",
      "| loss_q0   | 0.0323   |\n",
      "| loss_q1   | 0.00914  |\n",
      "| loss_q2   | 0.00256  |\n",
      "| loss_q3   | 0.000812 |\n",
      "| mse       | 0.0108   |\n",
      "| mse_q0    | 0.0323   |\n",
      "| mse_q1    | 0.00914  |\n",
      "| mse_q2    | 0.00256  |\n",
      "| mse_q3    | 0.000812 |\n",
      "| samples   | 9.76e+03 |\n",
      "| step      | 2.44e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.259    |\n",
      "| loss      | 0.00994  |\n",
      "| loss_q0   | 0.0278   |\n",
      "| loss_q1   | 0.00964  |\n",
      "| loss_q2   | 0.00218  |\n",
      "| loss_q3   | 0.000753 |\n",
      "| mse       | 0.00994  |\n",
      "| mse_q0    | 0.0278   |\n",
      "| mse_q1    | 0.00964  |\n",
      "| mse_q2    | 0.00218  |\n",
      "| mse_q3    | 0.000753 |\n",
      "| samples   | 9.8e+03  |\n",
      "| step      | 2.45e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.287    |\n",
      "| loss      | 0.0147   |\n",
      "| loss_q0   | 0.0457   |\n",
      "| loss_q1   | 0.00895  |\n",
      "| loss_q2   | 0.00234  |\n",
      "| loss_q3   | 0.000767 |\n",
      "| mse       | 0.0147   |\n",
      "| mse_q0    | 0.0457   |\n",
      "| mse_q1    | 0.00895  |\n",
      "| mse_q2    | 0.00234  |\n",
      "| mse_q3    | 0.000767 |\n",
      "| samples   | 9.84e+03 |\n",
      "| step      | 2.46e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.315    |\n",
      "| loss      | 0.0119   |\n",
      "| loss_q0   | 0.0378   |\n",
      "| loss_q1   | 0.00995  |\n",
      "| loss_q2   | 0.00274  |\n",
      "| loss_q3   | 0.000797 |\n",
      "| mse       | 0.0119   |\n",
      "| mse_q0    | 0.0378   |\n",
      "| mse_q1    | 0.00995  |\n",
      "| mse_q2    | 0.00274  |\n",
      "| mse_q3    | 0.000797 |\n",
      "| samples   | 9.88e+03 |\n",
      "| step      | 2.47e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.37     |\n",
      "| loss      | 0.0127   |\n",
      "| loss_q0   | 0.0386   |\n",
      "| loss_q1   | 0.00893  |\n",
      "| loss_q2   | 0.00262  |\n",
      "| loss_q3   | 0.000907 |\n",
      "| mse       | 0.0127   |\n",
      "| mse_q0    | 0.0386   |\n",
      "| mse_q1    | 0.00893  |\n",
      "| mse_q2    | 0.00262  |\n",
      "| mse_q3    | 0.000907 |\n",
      "| samples   | 9.92e+03 |\n",
      "| step      | 2.48e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.381    |\n",
      "| loss      | 0.0132   |\n",
      "| loss_q0   | 0.0452   |\n",
      "| loss_q1   | 0.00942  |\n",
      "| loss_q2   | 0.00297  |\n",
      "| loss_q3   | 0.000777 |\n",
      "| mse       | 0.0132   |\n",
      "| mse_q0    | 0.0452   |\n",
      "| mse_q1    | 0.00942  |\n",
      "| mse_q2    | 0.00297  |\n",
      "| mse_q3    | 0.000777 |\n",
      "| samples   | 9.96e+03 |\n",
      "| step      | 2.49e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.35     |\n",
      "| loss      | 0.0121   |\n",
      "| loss_q0   | 0.0311   |\n",
      "| loss_q1   | 0.00998  |\n",
      "| loss_q2   | 0.00223  |\n",
      "| loss_q3   | 0.000862 |\n",
      "| mse       | 0.0121   |\n",
      "| mse_q0    | 0.0311   |\n",
      "| mse_q1    | 0.00998  |\n",
      "| mse_q2    | 0.00223  |\n",
      "| mse_q3    | 0.000862 |\n",
      "| samples   | 1e+04    |\n",
      "| step      | 2.5e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.347    |\n",
      "| loss      | 0.012    |\n",
      "| loss_q0   | 0.0372   |\n",
      "| loss_q1   | 0.00873  |\n",
      "| loss_q2   | 0.00252  |\n",
      "| loss_q3   | 0.000757 |\n",
      "| mse       | 0.012    |\n",
      "| mse_q0    | 0.0372   |\n",
      "| mse_q1    | 0.00873  |\n",
      "| mse_q2    | 0.00252  |\n",
      "| mse_q3    | 0.000757 |\n",
      "| samples   | 1e+04    |\n",
      "| step      | 2.51e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.437    |\n",
      "| loss      | 0.0111   |\n",
      "| loss_q0   | 0.036    |\n",
      "| loss_q1   | 0.00955  |\n",
      "| loss_q2   | 0.00264  |\n",
      "| loss_q3   | 0.000771 |\n",
      "| mse       | 0.0111   |\n",
      "| mse_q0    | 0.036    |\n",
      "| mse_q1    | 0.00955  |\n",
      "| mse_q2    | 0.00264  |\n",
      "| mse_q3    | 0.000771 |\n",
      "| samples   | 1.01e+04 |\n",
      "| step      | 2.52e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.384    |\n",
      "| loss      | 0.0128   |\n",
      "| loss_q0   | 0.0393   |\n",
      "| loss_q1   | 0.0089   |\n",
      "| loss_q2   | 0.00275  |\n",
      "| loss_q3   | 0.000721 |\n",
      "| mse       | 0.0128   |\n",
      "| mse_q0    | 0.0393   |\n",
      "| mse_q1    | 0.0089   |\n",
      "| mse_q2    | 0.00275  |\n",
      "| mse_q3    | 0.000721 |\n",
      "| samples   | 1.01e+04 |\n",
      "| step      | 2.53e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.318    |\n",
      "| loss      | 0.0154   |\n",
      "| loss_q0   | 0.0398   |\n",
      "| loss_q1   | 0.0105   |\n",
      "| loss_q2   | 0.00266  |\n",
      "| loss_q3   | 0.000795 |\n",
      "| mse       | 0.0154   |\n",
      "| mse_q0    | 0.0398   |\n",
      "| mse_q1    | 0.0105   |\n",
      "| mse_q2    | 0.00266  |\n",
      "| mse_q3    | 0.000795 |\n",
      "| samples   | 1.02e+04 |\n",
      "| step      | 2.54e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.321    |\n",
      "| loss      | 0.0126   |\n",
      "| loss_q0   | 0.0356   |\n",
      "| loss_q1   | 0.0103   |\n",
      "| loss_q2   | 0.00237  |\n",
      "| loss_q3   | 0.000831 |\n",
      "| mse       | 0.0126   |\n",
      "| mse_q0    | 0.0356   |\n",
      "| mse_q1    | 0.0103   |\n",
      "| mse_q2    | 0.00237  |\n",
      "| mse_q3    | 0.000831 |\n",
      "| samples   | 1.02e+04 |\n",
      "| step      | 2.55e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.314    |\n",
      "| loss      | 0.0118   |\n",
      "| loss_q0   | 0.0389   |\n",
      "| loss_q1   | 0.00922  |\n",
      "| loss_q2   | 0.00237  |\n",
      "| loss_q3   | 0.000721 |\n",
      "| mse       | 0.0118   |\n",
      "| mse_q0    | 0.0389   |\n",
      "| mse_q1    | 0.00922  |\n",
      "| mse_q2    | 0.00237  |\n",
      "| mse_q3    | 0.000721 |\n",
      "| samples   | 1.02e+04 |\n",
      "| step      | 2.56e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.287    |\n",
      "| loss      | 0.0115   |\n",
      "| loss_q0   | 0.0359   |\n",
      "| loss_q1   | 0.00864  |\n",
      "| loss_q2   | 0.00214  |\n",
      "| loss_q3   | 0.000732 |\n",
      "| mse       | 0.0115   |\n",
      "| mse_q0    | 0.0359   |\n",
      "| mse_q1    | 0.00864  |\n",
      "| mse_q2    | 0.00214  |\n",
      "| mse_q3    | 0.000732 |\n",
      "| samples   | 1.03e+04 |\n",
      "| step      | 2.57e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.292    |\n",
      "| loss      | 0.0101   |\n",
      "| loss_q0   | 0.0317   |\n",
      "| loss_q1   | 0.0094   |\n",
      "| loss_q2   | 0.00292  |\n",
      "| loss_q3   | 0.000753 |\n",
      "| mse       | 0.0101   |\n",
      "| mse_q0    | 0.0317   |\n",
      "| mse_q1    | 0.0094   |\n",
      "| mse_q2    | 0.00292  |\n",
      "| mse_q3    | 0.000753 |\n",
      "| samples   | 1.03e+04 |\n",
      "| step      | 2.58e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.289    |\n",
      "| loss      | 0.0113   |\n",
      "| loss_q0   | 0.038    |\n",
      "| loss_q1   | 0.00876  |\n",
      "| loss_q2   | 0.00225  |\n",
      "| loss_q3   | 0.000699 |\n",
      "| mse       | 0.0113   |\n",
      "| mse_q0    | 0.038    |\n",
      "| mse_q1    | 0.00876  |\n",
      "| mse_q2    | 0.00225  |\n",
      "| mse_q3    | 0.000699 |\n",
      "| samples   | 1.04e+04 |\n",
      "| step      | 2.59e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.342    |\n",
      "| loss      | 0.00945  |\n",
      "| loss_q0   | 0.03     |\n",
      "| loss_q1   | 0.0089   |\n",
      "| loss_q2   | 0.0023   |\n",
      "| loss_q3   | 0.00074  |\n",
      "| mse       | 0.00945  |\n",
      "| mse_q0    | 0.03     |\n",
      "| mse_q1    | 0.0089   |\n",
      "| mse_q2    | 0.0023   |\n",
      "| mse_q3    | 0.00074  |\n",
      "| samples   | 1.04e+04 |\n",
      "| step      | 2.6e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.412    |\n",
      "| loss      | 0.0154   |\n",
      "| loss_q0   | 0.0515   |\n",
      "| loss_q1   | 0.00942  |\n",
      "| loss_q2   | 0.00244  |\n",
      "| loss_q3   | 0.000704 |\n",
      "| mse       | 0.0154   |\n",
      "| mse_q0    | 0.0515   |\n",
      "| mse_q1    | 0.00942  |\n",
      "| mse_q2    | 0.00244  |\n",
      "| mse_q3    | 0.000704 |\n",
      "| samples   | 1.04e+04 |\n",
      "| step      | 2.61e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.359    |\n",
      "| loss      | 0.0119   |\n",
      "| loss_q0   | 0.0326   |\n",
      "| loss_q1   | 0.00887  |\n",
      "| loss_q2   | 0.00247  |\n",
      "| loss_q3   | 0.000868 |\n",
      "| mse       | 0.0119   |\n",
      "| mse_q0    | 0.0326   |\n",
      "| mse_q1    | 0.00887  |\n",
      "| mse_q2    | 0.00247  |\n",
      "| mse_q3    | 0.000868 |\n",
      "| samples   | 1.05e+04 |\n",
      "| step      | 2.62e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.358    |\n",
      "| loss      | 0.0129   |\n",
      "| loss_q0   | 0.0353   |\n",
      "| loss_q1   | 0.00849  |\n",
      "| loss_q2   | 0.0025   |\n",
      "| loss_q3   | 0.000799 |\n",
      "| mse       | 0.0129   |\n",
      "| mse_q0    | 0.0353   |\n",
      "| mse_q1    | 0.00849  |\n",
      "| mse_q2    | 0.0025   |\n",
      "| mse_q3    | 0.000799 |\n",
      "| samples   | 1.05e+04 |\n",
      "| step      | 2.63e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.246    |\n",
      "| loss      | 0.0104   |\n",
      "| loss_q0   | 0.0381   |\n",
      "| loss_q1   | 0.00832  |\n",
      "| loss_q2   | 0.00211  |\n",
      "| loss_q3   | 0.000741 |\n",
      "| mse       | 0.0104   |\n",
      "| mse_q0    | 0.0381   |\n",
      "| mse_q1    | 0.00832  |\n",
      "| mse_q2    | 0.00211  |\n",
      "| mse_q3    | 0.000741 |\n",
      "| samples   | 1.06e+04 |\n",
      "| step      | 2.64e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.343    |\n",
      "| loss      | 0.01     |\n",
      "| loss_q0   | 0.0303   |\n",
      "| loss_q1   | 0.00978  |\n",
      "| loss_q2   | 0.00248  |\n",
      "| loss_q3   | 0.000735 |\n",
      "| mse       | 0.01     |\n",
      "| mse_q0    | 0.0303   |\n",
      "| mse_q1    | 0.00978  |\n",
      "| mse_q2    | 0.00248  |\n",
      "| mse_q3    | 0.000735 |\n",
      "| samples   | 1.06e+04 |\n",
      "| step      | 2.65e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.304    |\n",
      "| loss      | 0.0112   |\n",
      "| loss_q0   | 0.0344   |\n",
      "| loss_q1   | 0.00839  |\n",
      "| loss_q2   | 0.00243  |\n",
      "| loss_q3   | 0.000746 |\n",
      "| mse       | 0.0112   |\n",
      "| mse_q0    | 0.0344   |\n",
      "| mse_q1    | 0.00839  |\n",
      "| mse_q2    | 0.00243  |\n",
      "| mse_q3    | 0.000746 |\n",
      "| samples   | 1.06e+04 |\n",
      "| step      | 2.66e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.404    |\n",
      "| loss      | 0.0156   |\n",
      "| loss_q0   | 0.0481   |\n",
      "| loss_q1   | 0.00858  |\n",
      "| loss_q2   | 0.00269  |\n",
      "| loss_q3   | 0.000742 |\n",
      "| mse       | 0.0156   |\n",
      "| mse_q0    | 0.0481   |\n",
      "| mse_q1    | 0.00858  |\n",
      "| mse_q2    | 0.00269  |\n",
      "| mse_q3    | 0.000742 |\n",
      "| samples   | 1.07e+04 |\n",
      "| step      | 2.67e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.355    |\n",
      "| loss      | 0.0151   |\n",
      "| loss_q0   | 0.0402   |\n",
      "| loss_q1   | 0.00987  |\n",
      "| loss_q2   | 0.00244  |\n",
      "| loss_q3   | 0.000749 |\n",
      "| mse       | 0.0151   |\n",
      "| mse_q0    | 0.0402   |\n",
      "| mse_q1    | 0.00987  |\n",
      "| mse_q2    | 0.00244  |\n",
      "| mse_q3    | 0.000749 |\n",
      "| samples   | 1.07e+04 |\n",
      "| step      | 2.68e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.354    |\n",
      "| loss      | 0.015    |\n",
      "| loss_q0   | 0.0367   |\n",
      "| loss_q1   | 0.00877  |\n",
      "| loss_q2   | 0.0023   |\n",
      "| loss_q3   | 0.000768 |\n",
      "| mse       | 0.015    |\n",
      "| mse_q0    | 0.0367   |\n",
      "| mse_q1    | 0.00877  |\n",
      "| mse_q2    | 0.0023   |\n",
      "| mse_q3    | 0.000768 |\n",
      "| samples   | 1.08e+04 |\n",
      "| step      | 2.69e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.389    |\n",
      "| loss      | 0.0127   |\n",
      "| loss_q0   | 0.0406   |\n",
      "| loss_q1   | 0.00806  |\n",
      "| loss_q2   | 0.0028   |\n",
      "| loss_q3   | 0.000846 |\n",
      "| mse       | 0.0127   |\n",
      "| mse_q0    | 0.0406   |\n",
      "| mse_q1    | 0.00806  |\n",
      "| mse_q2    | 0.0028   |\n",
      "| mse_q3    | 0.000846 |\n",
      "| samples   | 1.08e+04 |\n",
      "| step      | 2.7e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.341    |\n",
      "| loss      | 0.00998  |\n",
      "| loss_q0   | 0.0347   |\n",
      "| loss_q1   | 0.00885  |\n",
      "| loss_q2   | 0.00234  |\n",
      "| loss_q3   | 0.000765 |\n",
      "| mse       | 0.00998  |\n",
      "| mse_q0    | 0.0347   |\n",
      "| mse_q1    | 0.00885  |\n",
      "| mse_q2    | 0.00234  |\n",
      "| mse_q3    | 0.000765 |\n",
      "| samples   | 1.08e+04 |\n",
      "| step      | 2.71e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.412    |\n",
      "| loss      | 0.013    |\n",
      "| loss_q0   | 0.0393   |\n",
      "| loss_q1   | 0.00875  |\n",
      "| loss_q2   | 0.00267  |\n",
      "| loss_q3   | 0.00079  |\n",
      "| mse       | 0.013    |\n",
      "| mse_q0    | 0.0393   |\n",
      "| mse_q1    | 0.00875  |\n",
      "| mse_q2    | 0.00267  |\n",
      "| mse_q3    | 0.00079  |\n",
      "| samples   | 1.09e+04 |\n",
      "| step      | 2.72e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.439    |\n",
      "| loss      | 0.0133   |\n",
      "| loss_q0   | 0.0395   |\n",
      "| loss_q1   | 0.00829  |\n",
      "| loss_q2   | 0.00259  |\n",
      "| loss_q3   | 0.000852 |\n",
      "| mse       | 0.0133   |\n",
      "| mse_q0    | 0.0395   |\n",
      "| mse_q1    | 0.00829  |\n",
      "| mse_q2    | 0.00259  |\n",
      "| mse_q3    | 0.000852 |\n",
      "| samples   | 1.09e+04 |\n",
      "| step      | 2.73e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.408    |\n",
      "| loss      | 0.0167   |\n",
      "| loss_q0   | 0.0446   |\n",
      "| loss_q1   | 0.00894  |\n",
      "| loss_q2   | 0.00228  |\n",
      "| loss_q3   | 0.000806 |\n",
      "| mse       | 0.0167   |\n",
      "| mse_q0    | 0.0446   |\n",
      "| mse_q1    | 0.00894  |\n",
      "| mse_q2    | 0.00228  |\n",
      "| mse_q3    | 0.000806 |\n",
      "| samples   | 1.1e+04  |\n",
      "| step      | 2.74e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.325    |\n",
      "| loss      | 0.0109   |\n",
      "| loss_q0   | 0.03     |\n",
      "| loss_q1   | 0.00838  |\n",
      "| loss_q2   | 0.00294  |\n",
      "| loss_q3   | 0.000726 |\n",
      "| mse       | 0.0109   |\n",
      "| mse_q0    | 0.03     |\n",
      "| mse_q1    | 0.00838  |\n",
      "| mse_q2    | 0.00294  |\n",
      "| mse_q3    | 0.000726 |\n",
      "| samples   | 1.1e+04  |\n",
      "| step      | 2.75e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.287    |\n",
      "| loss      | 0.0131   |\n",
      "| loss_q0   | 0.0394   |\n",
      "| loss_q1   | 0.00862  |\n",
      "| loss_q2   | 0.00269  |\n",
      "| loss_q3   | 0.000668 |\n",
      "| mse       | 0.0131   |\n",
      "| mse_q0    | 0.0394   |\n",
      "| mse_q1    | 0.00862  |\n",
      "| mse_q2    | 0.00269  |\n",
      "| mse_q3    | 0.000668 |\n",
      "| samples   | 1.1e+04  |\n",
      "| step      | 2.76e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.321    |\n",
      "| loss      | 0.0105   |\n",
      "| loss_q0   | 0.0388   |\n",
      "| loss_q1   | 0.00876  |\n",
      "| loss_q2   | 0.00233  |\n",
      "| loss_q3   | 0.000791 |\n",
      "| mse       | 0.0105   |\n",
      "| mse_q0    | 0.0388   |\n",
      "| mse_q1    | 0.00876  |\n",
      "| mse_q2    | 0.00233  |\n",
      "| mse_q3    | 0.000791 |\n",
      "| samples   | 1.11e+04 |\n",
      "| step      | 2.77e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.277    |\n",
      "| loss      | 0.0141   |\n",
      "| loss_q0   | 0.0417   |\n",
      "| loss_q1   | 0.0088   |\n",
      "| loss_q2   | 0.00291  |\n",
      "| loss_q3   | 0.000799 |\n",
      "| mse       | 0.0141   |\n",
      "| mse_q0    | 0.0417   |\n",
      "| mse_q1    | 0.0088   |\n",
      "| mse_q2    | 0.00291  |\n",
      "| mse_q3    | 0.000799 |\n",
      "| samples   | 1.11e+04 |\n",
      "| step      | 2.78e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.304    |\n",
      "| loss      | 0.0111   |\n",
      "| loss_q0   | 0.0296   |\n",
      "| loss_q1   | 0.00922  |\n",
      "| loss_q2   | 0.00245  |\n",
      "| loss_q3   | 0.000775 |\n",
      "| mse       | 0.0111   |\n",
      "| mse_q0    | 0.0296   |\n",
      "| mse_q1    | 0.00922  |\n",
      "| mse_q2    | 0.00245  |\n",
      "| mse_q3    | 0.000775 |\n",
      "| samples   | 1.12e+04 |\n",
      "| step      | 2.79e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.33     |\n",
      "| loss      | 0.0118   |\n",
      "| loss_q0   | 0.042    |\n",
      "| loss_q1   | 0.01     |\n",
      "| loss_q2   | 0.00227  |\n",
      "| loss_q3   | 0.000756 |\n",
      "| mse       | 0.0118   |\n",
      "| mse_q0    | 0.042    |\n",
      "| mse_q1    | 0.01     |\n",
      "| mse_q2    | 0.00227  |\n",
      "| mse_q3    | 0.000756 |\n",
      "| samples   | 1.12e+04 |\n",
      "| step      | 2.8e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.225    |\n",
      "| loss      | 0.0109   |\n",
      "| loss_q0   | 0.0388   |\n",
      "| loss_q1   | 0.00804  |\n",
      "| loss_q2   | 0.00238  |\n",
      "| loss_q3   | 0.000711 |\n",
      "| mse       | 0.0109   |\n",
      "| mse_q0    | 0.0388   |\n",
      "| mse_q1    | 0.00804  |\n",
      "| mse_q2    | 0.00238  |\n",
      "| mse_q3    | 0.000711 |\n",
      "| samples   | 1.12e+04 |\n",
      "| step      | 2.81e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.249    |\n",
      "| loss      | 0.0121   |\n",
      "| loss_q0   | 0.0358   |\n",
      "| loss_q1   | 0.00937  |\n",
      "| loss_q2   | 0.0025   |\n",
      "| loss_q3   | 0.000731 |\n",
      "| mse       | 0.0121   |\n",
      "| mse_q0    | 0.0358   |\n",
      "| mse_q1    | 0.00937  |\n",
      "| mse_q2    | 0.0025   |\n",
      "| mse_q3    | 0.000731 |\n",
      "| samples   | 1.13e+04 |\n",
      "| step      | 2.82e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.321    |\n",
      "| loss      | 0.014    |\n",
      "| loss_q0   | 0.0438   |\n",
      "| loss_q1   | 0.00843  |\n",
      "| loss_q2   | 0.00241  |\n",
      "| loss_q3   | 0.000702 |\n",
      "| mse       | 0.014    |\n",
      "| mse_q0    | 0.0438   |\n",
      "| mse_q1    | 0.00843  |\n",
      "| mse_q2    | 0.00241  |\n",
      "| mse_q3    | 0.000702 |\n",
      "| samples   | 1.13e+04 |\n",
      "| step      | 2.83e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.348    |\n",
      "| loss      | 0.0118   |\n",
      "| loss_q0   | 0.0394   |\n",
      "| loss_q1   | 0.00839  |\n",
      "| loss_q2   | 0.00263  |\n",
      "| loss_q3   | 0.000747 |\n",
      "| mse       | 0.0118   |\n",
      "| mse_q0    | 0.0394   |\n",
      "| mse_q1    | 0.00839  |\n",
      "| mse_q2    | 0.00263  |\n",
      "| mse_q3    | 0.000747 |\n",
      "| samples   | 1.14e+04 |\n",
      "| step      | 2.84e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.349    |\n",
      "| loss      | 0.0114   |\n",
      "| loss_q0   | 0.0338   |\n",
      "| loss_q1   | 0.00911  |\n",
      "| loss_q2   | 0.00272  |\n",
      "| loss_q3   | 0.0008   |\n",
      "| mse       | 0.0114   |\n",
      "| mse_q0    | 0.0338   |\n",
      "| mse_q1    | 0.00911  |\n",
      "| mse_q2    | 0.00272  |\n",
      "| mse_q3    | 0.0008   |\n",
      "| samples   | 1.14e+04 |\n",
      "| step      | 2.85e+03 |\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "| grad_norm | 0.351    |\n",
      "| loss      | 0.0111   |\n",
      "| loss_q0   | 0.0364   |\n",
      "| loss_q1   | 0.00933  |\n",
      "| loss_q2   | 0.00232  |\n",
      "| loss_q3   | 0.000752 |\n",
      "| mse       | 0.0111   |\n",
      "| mse_q0    | 0.0364   |\n",
      "| mse_q1    | 0.00933  |\n",
      "| mse_q2    | 0.00232  |\n",
      "| mse_q3    | 0.000752 |\n",
      "| samples   | 1.14e+04 |\n",
      "| step      | 2.86e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.415    |\n",
      "| loss      | 0.0151   |\n",
      "| loss_q0   | 0.0468   |\n",
      "| loss_q1   | 0.0103   |\n",
      "| loss_q2   | 0.00246  |\n",
      "| loss_q3   | 0.000721 |\n",
      "| mse       | 0.0151   |\n",
      "| mse_q0    | 0.0468   |\n",
      "| mse_q1    | 0.0103   |\n",
      "| mse_q2    | 0.00246  |\n",
      "| mse_q3    | 0.000721 |\n",
      "| samples   | 1.15e+04 |\n",
      "| step      | 2.87e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.411    |\n",
      "| loss      | 0.0122   |\n",
      "| loss_q0   | 0.0405   |\n",
      "| loss_q1   | 0.00945  |\n",
      "| loss_q2   | 0.0026   |\n",
      "| loss_q3   | 0.000876 |\n",
      "| mse       | 0.0122   |\n",
      "| mse_q0    | 0.0405   |\n",
      "| mse_q1    | 0.00945  |\n",
      "| mse_q2    | 0.0026   |\n",
      "| mse_q3    | 0.000876 |\n",
      "| samples   | 1.15e+04 |\n",
      "| step      | 2.88e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.382    |\n",
      "| loss      | 0.0111   |\n",
      "| loss_q0   | 0.0317   |\n",
      "| loss_q1   | 0.00958  |\n",
      "| loss_q2   | 0.00245  |\n",
      "| loss_q3   | 0.000819 |\n",
      "| mse       | 0.0111   |\n",
      "| mse_q0    | 0.0317   |\n",
      "| mse_q1    | 0.00958  |\n",
      "| mse_q2    | 0.00245  |\n",
      "| mse_q3    | 0.000819 |\n",
      "| samples   | 1.16e+04 |\n",
      "| step      | 2.89e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.403    |\n",
      "| loss      | 0.014    |\n",
      "| loss_q0   | 0.0357   |\n",
      "| loss_q1   | 0.00942  |\n",
      "| loss_q2   | 0.00245  |\n",
      "| loss_q3   | 0.000855 |\n",
      "| mse       | 0.014    |\n",
      "| mse_q0    | 0.0357   |\n",
      "| mse_q1    | 0.00942  |\n",
      "| mse_q2    | 0.00245  |\n",
      "| mse_q3    | 0.000855 |\n",
      "| samples   | 1.16e+04 |\n",
      "| step      | 2.9e+03  |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.388    |\n",
      "| loss      | 0.0123   |\n",
      "| loss_q0   | 0.0334   |\n",
      "| loss_q1   | 0.00904  |\n",
      "| loss_q2   | 0.00253  |\n",
      "| loss_q3   | 0.000858 |\n",
      "| mse       | 0.0123   |\n",
      "| mse_q0    | 0.0334   |\n",
      "| mse_q1    | 0.00904  |\n",
      "| mse_q2    | 0.00253  |\n",
      "| mse_q3    | 0.000858 |\n",
      "| samples   | 1.16e+04 |\n",
      "| step      | 2.91e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.457    |\n",
      "| loss      | 0.0138   |\n",
      "| loss_q0   | 0.0406   |\n",
      "| loss_q1   | 0.00815  |\n",
      "| loss_q2   | 0.00244  |\n",
      "| loss_q3   | 0.000849 |\n",
      "| mse       | 0.0138   |\n",
      "| mse_q0    | 0.0406   |\n",
      "| mse_q1    | 0.00815  |\n",
      "| mse_q2    | 0.00244  |\n",
      "| mse_q3    | 0.000849 |\n",
      "| samples   | 1.17e+04 |\n",
      "| step      | 2.92e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.357    |\n",
      "| loss      | 0.0111   |\n",
      "| loss_q0   | 0.0337   |\n",
      "| loss_q1   | 0.0087   |\n",
      "| loss_q2   | 0.00236  |\n",
      "| loss_q3   | 0.000775 |\n",
      "| mse       | 0.0111   |\n",
      "| mse_q0    | 0.0337   |\n",
      "| mse_q1    | 0.0087   |\n",
      "| mse_q2    | 0.00236  |\n",
      "| mse_q3    | 0.000775 |\n",
      "| samples   | 1.17e+04 |\n",
      "| step      | 2.93e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.41     |\n",
      "| loss      | 0.0127   |\n",
      "| loss_q0   | 0.0382   |\n",
      "| loss_q1   | 0.00796  |\n",
      "| loss_q2   | 0.00228  |\n",
      "| loss_q3   | 0.000799 |\n",
      "| mse       | 0.0127   |\n",
      "| mse_q0    | 0.0382   |\n",
      "| mse_q1    | 0.00796  |\n",
      "| mse_q2    | 0.00228  |\n",
      "| mse_q3    | 0.000799 |\n",
      "| samples   | 1.18e+04 |\n",
      "| step      | 2.94e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.409    |\n",
      "| loss      | 0.0131   |\n",
      "| loss_q0   | 0.0344   |\n",
      "| loss_q1   | 0.00924  |\n",
      "| loss_q2   | 0.00298  |\n",
      "| loss_q3   | 0.000864 |\n",
      "| mse       | 0.0131   |\n",
      "| mse_q0    | 0.0344   |\n",
      "| mse_q1    | 0.00924  |\n",
      "| mse_q2    | 0.00298  |\n",
      "| mse_q3    | 0.000864 |\n",
      "| samples   | 1.18e+04 |\n",
      "| step      | 2.95e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.41     |\n",
      "| loss      | 0.0106   |\n",
      "| loss_q0   | 0.0357   |\n",
      "| loss_q1   | 0.00882  |\n",
      "| loss_q2   | 0.00259  |\n",
      "| loss_q3   | 0.000911 |\n",
      "| mse       | 0.0106   |\n",
      "| mse_q0    | 0.0357   |\n",
      "| mse_q1    | 0.00882  |\n",
      "| mse_q2    | 0.00259  |\n",
      "| mse_q3    | 0.000911 |\n",
      "| samples   | 1.18e+04 |\n",
      "| step      | 2.96e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.353    |\n",
      "| loss      | 0.0114   |\n",
      "| loss_q0   | 0.0362   |\n",
      "| loss_q1   | 0.00842  |\n",
      "| loss_q2   | 0.00229  |\n",
      "| loss_q3   | 0.000709 |\n",
      "| mse       | 0.0114   |\n",
      "| mse_q0    | 0.0362   |\n",
      "| mse_q1    | 0.00842  |\n",
      "| mse_q2    | 0.00229  |\n",
      "| mse_q3    | 0.000709 |\n",
      "| samples   | 1.19e+04 |\n",
      "| step      | 2.97e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.301    |\n",
      "| loss      | 0.0104   |\n",
      "| loss_q0   | 0.0299   |\n",
      "| loss_q1   | 0.00836  |\n",
      "| loss_q2   | 0.00212  |\n",
      "| loss_q3   | 0.000776 |\n",
      "| mse       | 0.0104   |\n",
      "| mse_q0    | 0.0299   |\n",
      "| mse_q1    | 0.00836  |\n",
      "| mse_q2    | 0.00212  |\n",
      "| mse_q3    | 0.000776 |\n",
      "| samples   | 1.19e+04 |\n",
      "| step      | 2.98e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.396    |\n",
      "| loss      | 0.0116   |\n",
      "| loss_q0   | 0.0391   |\n",
      "| loss_q1   | 0.00815  |\n",
      "| loss_q2   | 0.00253  |\n",
      "| loss_q3   | 0.000773 |\n",
      "| mse       | 0.0116   |\n",
      "| mse_q0    | 0.0391   |\n",
      "| mse_q1    | 0.00815  |\n",
      "| mse_q2    | 0.00253  |\n",
      "| mse_q3    | 0.000773 |\n",
      "| samples   | 1.2e+04  |\n",
      "| step      | 2.99e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.341    |\n",
      "| loss      | 0.0115   |\n",
      "| loss_q0   | 0.0359   |\n",
      "| loss_q1   | 0.008    |\n",
      "| loss_q2   | 0.00263  |\n",
      "| loss_q3   | 0.000731 |\n",
      "| mse       | 0.0115   |\n",
      "| mse_q0    | 0.0359   |\n",
      "| mse_q1    | 0.008    |\n",
      "| mse_q2    | 0.00263  |\n",
      "| mse_q3    | 0.000731 |\n",
      "| samples   | 1.2e+04  |\n",
      "| step      | 3e+03    |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.381    |\n",
      "| loss      | 0.0138   |\n",
      "| loss_q0   | 0.0375   |\n",
      "| loss_q1   | 0.00942  |\n",
      "| loss_q2   | 0.00252  |\n",
      "| loss_q3   | 0.000809 |\n",
      "| mse       | 0.0138   |\n",
      "| mse_q0    | 0.0375   |\n",
      "| mse_q1    | 0.00942  |\n",
      "| mse_q2    | 0.00252  |\n",
      "| mse_q3    | 0.000809 |\n",
      "| samples   | 1.2e+04  |\n",
      "| step      | 3.01e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.278    |\n",
      "| loss      | 0.0114   |\n",
      "| loss_q0   | 0.0353   |\n",
      "| loss_q1   | 0.00872  |\n",
      "| loss_q2   | 0.00259  |\n",
      "| loss_q3   | 0.000722 |\n",
      "| mse       | 0.0114   |\n",
      "| mse_q0    | 0.0353   |\n",
      "| mse_q1    | 0.00872  |\n",
      "| mse_q2    | 0.00259  |\n",
      "| mse_q3    | 0.000722 |\n",
      "| samples   | 1.21e+04 |\n",
      "| step      | 3.02e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.273    |\n",
      "| loss      | 0.0107   |\n",
      "| loss_q0   | 0.0274   |\n",
      "| loss_q1   | 0.00942  |\n",
      "| loss_q2   | 0.00258  |\n",
      "| loss_q3   | 0.000779 |\n",
      "| mse       | 0.0107   |\n",
      "| mse_q0    | 0.0274   |\n",
      "| mse_q1    | 0.00942  |\n",
      "| mse_q2    | 0.00258  |\n",
      "| mse_q3    | 0.000779 |\n",
      "| samples   | 1.21e+04 |\n",
      "| step      | 3.03e+03 |\n",
      "------------------------\n",
      "------------------------\n",
      "| grad_norm | 0.24     |\n",
      "| loss      | 0.0125   |\n",
      "| loss_q0   | 0.0351   |\n",
      "| loss_q1   | 0.00906  |\n",
      "| loss_q2   | 0.00216  |\n",
      "| loss_q3   | 0.000642 |\n",
      "| mse       | 0.0125   |\n",
      "| mse_q0    | 0.0351   |\n",
      "| mse_q1    | 0.00906  |\n",
      "| mse_q2    | 0.00216  |\n",
      "| mse_q3    | 0.000642 |\n",
      "| samples   | 1.22e+04 |\n",
      "| step      | 3.04e+03 |\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.run_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daecf03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
